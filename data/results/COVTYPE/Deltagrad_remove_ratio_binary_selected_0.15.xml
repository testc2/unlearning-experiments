<data>
<Generate_Dataset/>
<Training>
Train - Epoch 0, Batch: 0, Loss: 0.695010
Train - Epoch 0, Batch: 1, Loss: 0.691716
Train - Epoch 0, Batch: 2, Loss: 0.698302
Train - Epoch 0, Batch: 3, Loss: 0.693168
Train - Epoch 0, Batch: 4, Loss: 0.691853
Train - Epoch 0, Batch: 5, Loss: 0.690012
Train - Epoch 0, Batch: 6, Loss: 0.693955
Train - Epoch 0, Batch: 7, Loss: 0.691763
Train - Epoch 0, Batch: 8, Loss: 0.690955
Train - Epoch 0, Batch: 9, Loss: 0.690886
Train - Epoch 0, Batch: 10, Loss: 0.689377
Train - Epoch 0, Batch: 11, Loss: 0.687271
Train - Epoch 0, Batch: 12, Loss: 0.683330
Train - Epoch 0, Batch: 13, Loss: 0.686153
Train - Epoch 0, Batch: 14, Loss: 0.685538
Train - Epoch 0, Batch: 15, Loss: 0.684668
Train - Epoch 0, Batch: 16, Loss: 0.683772
Train - Epoch 0, Batch: 17, Loss: 0.688985
Train - Epoch 0, Batch: 18, Loss: 0.684070
Train - Epoch 0, Batch: 19, Loss: 0.682562
Train - Epoch 0, Batch: 20, Loss: 0.683542
Train - Epoch 0, Batch: 21, Loss: 0.684023
Train - Epoch 0, Batch: 22, Loss: 0.678753
Train - Epoch 0, Batch: 23, Loss: 0.679202
Train - Epoch 0, Batch: 24, Loss: 0.683569
Train - Epoch 0, Batch: 25, Loss: 0.681252
Train - Epoch 0, Batch: 26, Loss: 0.682335
Train - Epoch 0, Batch: 27, Loss: 0.678679
Train - Epoch 0, Batch: 28, Loss: 0.681889
Train - Epoch 0, Batch: 29, Loss: 0.678093
Train - Epoch 0, Batch: 30, Loss: 0.677210
Train - Epoch 0, Batch: 31, Loss: 0.676420
Train - Epoch 0, Batch: 32, Loss: 0.681333
Train - Epoch 0, Batch: 33, Loss: 0.682154
Train - Epoch 0, Batch: 34, Loss: 0.679801
Train - Epoch 0, Batch: 35, Loss: 0.675368
Train - Epoch 0, Batch: 36, Loss: 0.678033
Train - Epoch 0, Batch: 37, Loss: 0.678001
Train - Epoch 0, Batch: 38, Loss: 0.675866
Train - Epoch 0, Batch: 39, Loss: 0.675504
Train - Epoch 0, Batch: 40, Loss: 0.671528
Train - Epoch 0, Batch: 41, Loss: 0.672723
Train - Epoch 0, Batch: 42, Loss: 0.673858
Train - Epoch 0, Batch: 43, Loss: 0.674499
Train - Epoch 0, Batch: 44, Loss: 0.674349
Train - Epoch 0, Batch: 45, Loss: 0.674527
Train - Epoch 0, Batch: 46, Loss: 0.668979
Train - Epoch 0, Batch: 47, Loss: 0.668183
Train - Epoch 0, Batch: 48, Loss: 0.671026
Train - Epoch 0, Batch: 49, Loss: 0.674491
Train - Epoch 0, Batch: 50, Loss: 0.670824
Train - Epoch 0, Batch: 51, Loss: 0.670101
Train - Epoch 0, Batch: 52, Loss: 0.670211
Train - Epoch 0, Batch: 53, Loss: 0.672382
Train - Epoch 0, Batch: 54, Loss: 0.667905
Train - Epoch 0, Batch: 55, Loss: 0.673014
Train - Epoch 0, Batch: 56, Loss: 0.665153
Train - Epoch 0, Batch: 57, Loss: 0.669382
Train - Epoch 0, Batch: 58, Loss: 0.664635
Train - Epoch 0, Batch: 59, Loss: 0.664440
Train - Epoch 0, Batch: 60, Loss: 0.667268
Train - Epoch 0, Batch: 61, Loss: 0.665725
Train - Epoch 0, Batch: 62, Loss: 0.670271
Train - Epoch 0, Batch: 63, Loss: 0.670468
Train - Epoch 0, Batch: 64, Loss: 0.667396
Train - Epoch 0, Batch: 65, Loss: 0.663636
Train - Epoch 0, Batch: 66, Loss: 0.664490
Train - Epoch 0, Batch: 67, Loss: 0.670462
Train - Epoch 0, Batch: 68, Loss: 0.662599
Train - Epoch 0, Batch: 69, Loss: 0.663282
Train - Epoch 0, Batch: 70, Loss: 0.661481
Train - Epoch 0, Batch: 71, Loss: 0.660357
Train - Epoch 0, Batch: 72, Loss: 0.659783
Train - Epoch 0, Batch: 73, Loss: 0.663727
Train - Epoch 0, Batch: 74, Loss: 0.664516
Train - Epoch 0, Batch: 75, Loss: 0.662565
Train - Epoch 0, Batch: 76, Loss: 0.661032
Train - Epoch 0, Batch: 77, Loss: 0.656561
Train - Epoch 0, Batch: 78, Loss: 0.657950
Train - Epoch 0, Batch: 79, Loss: 0.663242
Train - Epoch 0, Batch: 80, Loss: 0.660536
Train - Epoch 0, Batch: 81, Loss: 0.650823
Train - Epoch 0, Batch: 82, Loss: 0.666444
Train - Epoch 0, Batch: 83, Loss: 0.659022
Train - Epoch 0, Batch: 84, Loss: 0.657270
Train - Epoch 0, Batch: 85, Loss: 0.661599
Train - Epoch 0, Batch: 86, Loss: 0.658665
Train - Epoch 0, Batch: 87, Loss: 0.659222
Train - Epoch 0, Batch: 88, Loss: 0.650277
Train - Epoch 0, Batch: 89, Loss: 0.659423
Train - Epoch 0, Batch: 90, Loss: 0.664819
Train - Epoch 0, Batch: 91, Loss: 0.658398
Train - Epoch 0, Batch: 92, Loss: 0.654987
Train - Epoch 0, Batch: 93, Loss: 0.662314
Train - Epoch 0, Batch: 94, Loss: 0.659162
Train - Epoch 0, Batch: 95, Loss: 0.657818
Train - Epoch 0, Batch: 96, Loss: 0.653172
Train - Epoch 0, Batch: 97, Loss: 0.656179
Train - Epoch 0, Batch: 98, Loss: 0.656277
Train - Epoch 0, Batch: 99, Loss: 0.663259
Train - Epoch 0, Batch: 100, Loss: 0.658705
Train - Epoch 0, Batch: 101, Loss: 0.654295
Train - Epoch 0, Batch: 102, Loss: 0.651543
Train - Epoch 0, Batch: 103, Loss: 0.656346
Train - Epoch 0, Batch: 104, Loss: 0.653368
Train - Epoch 0, Batch: 105, Loss: 0.649814
Train - Epoch 0, Batch: 106, Loss: 0.652155
Train - Epoch 0, Batch: 107, Loss: 0.659800
Train - Epoch 0, Batch: 108, Loss: 0.653236
Train - Epoch 0, Batch: 109, Loss: 0.651570
Train - Epoch 0, Batch: 110, Loss: 0.650047
Train - Epoch 0, Batch: 111, Loss: 0.658197
Train - Epoch 0, Batch: 112, Loss: 0.648463
Train - Epoch 0, Batch: 113, Loss: 0.659081
Train - Epoch 0, Batch: 114, Loss: 0.651455
Train - Epoch 0, Batch: 115, Loss: 0.654431
Train - Epoch 0, Batch: 116, Loss: 0.649280
Train - Epoch 0, Batch: 117, Loss: 0.648523
Train - Epoch 0, Batch: 118, Loss: 0.658356
Train - Epoch 0, Batch: 119, Loss: 0.652201
Train - Epoch 0, Batch: 120, Loss: 0.653398
Train - Epoch 0, Batch: 121, Loss: 0.641397
Train - Epoch 0, Batch: 122, Loss: 0.645253
Train - Epoch 0, Batch: 123, Loss: 0.636848
Train - Epoch 0, Batch: 124, Loss: 0.646567
Train - Epoch 0, Batch: 125, Loss: 0.644465
Train - Epoch 0, Batch: 126, Loss: 0.652616
Train - Epoch 0, Batch: 127, Loss: 0.650626
Train - Epoch 0, Batch: 128, Loss: 0.655014
Train - Epoch 0, Batch: 129, Loss: 0.645164
Train - Epoch 0, Batch: 130, Loss: 0.649377
Train - Epoch 0, Batch: 131, Loss: 0.642908
Train - Epoch 0, Batch: 132, Loss: 0.651180
Train - Epoch 0, Batch: 133, Loss: 0.654369
Train - Epoch 0, Batch: 134, Loss: 0.656658
Train - Epoch 0, Batch: 135, Loss: 0.639388
Train - Epoch 0, Batch: 136, Loss: 0.653243
Train - Epoch 0, Batch: 137, Loss: 0.628773
Train - Epoch 0, Batch: 138, Loss: 0.641383
Train - Epoch 0, Batch: 139, Loss: 0.652193
Train - Epoch 0, Batch: 140, Loss: 0.649105
Train - Epoch 0, Batch: 141, Loss: 0.645788
Train - Epoch 0, Batch: 142, Loss: 0.656222
Train - Epoch 0, Batch: 143, Loss: 0.652292
Train - Epoch 0, Batch: 144, Loss: 0.639930
Train - Epoch 0, Batch: 145, Loss: 0.643566
Train - Epoch 0, Batch: 146, Loss: 0.653040
Train - Epoch 0, Batch: 147, Loss: 0.642653
Train - Epoch 0, Batch: 148, Loss: 0.652678
Train - Epoch 0, Batch: 149, Loss: 0.640211
Train - Epoch 0, Batch: 150, Loss: 0.644563
Train - Epoch 0, Batch: 151, Loss: 0.650714
Train - Epoch 0, Batch: 152, Loss: 0.643356
Train - Epoch 0, Batch: 153, Loss: 0.648411
Train - Epoch 0, Batch: 154, Loss: 0.636715
Train - Epoch 0, Batch: 155, Loss: 0.657522
Train - Epoch 0, Batch: 156, Loss: 0.635734
Train - Epoch 0, Batch: 157, Loss: 0.649585
Train - Epoch 0, Batch: 158, Loss: 0.642365
Train - Epoch 0, Batch: 159, Loss: 0.640020
Train - Epoch 0, Batch: 160, Loss: 0.643794
Train - Epoch 0, Batch: 161, Loss: 0.642947
Train - Epoch 0, Batch: 162, Loss: 0.644925
Train - Epoch 0, Batch: 163, Loss: 0.641981
Train - Epoch 0, Batch: 164, Loss: 0.640464
Train - Epoch 0, Batch: 165, Loss: 0.640387
Train - Epoch 0, Batch: 166, Loss: 0.647269
Train - Epoch 0, Batch: 167, Loss: 0.644878
Train - Epoch 0, Batch: 168, Loss: 0.644890
Train - Epoch 0, Batch: 169, Loss: 0.621873
Train - Epoch 0, Batch: 170, Loss: 0.633747
Train - Epoch 0, Batch: 171, Loss: 0.636635
Train - Epoch 0, Batch: 172, Loss: 0.652661
Train - Epoch 0, Batch: 173, Loss: 0.641039
Train - Epoch 0, Batch: 174, Loss: 0.643678
Train - Epoch 0, Batch: 175, Loss: 0.635016
Train - Epoch 0, Batch: 176, Loss: 0.647464
Train - Epoch 0, Batch: 177, Loss: 0.636222
Train - Epoch 0, Batch: 178, Loss: 0.641480
Train - Epoch 0, Batch: 179, Loss: 0.630200
Train - Epoch 0, Batch: 180, Loss: 0.622944
Train - Epoch 0, Batch: 181, Loss: 0.639988
Train - Epoch 0, Batch: 182, Loss: 0.645520
Train - Epoch 0, Batch: 183, Loss: 0.636981
Train - Epoch 0, Batch: 184, Loss: 0.646951
Train - Epoch 0, Batch: 185, Loss: 0.633980
Train - Epoch 0, Batch: 186, Loss: 0.637850
Train - Epoch 0, Batch: 187, Loss: 0.632948
Train - Epoch 0, Batch: 188, Loss: 0.640462
Train - Epoch 0, Batch: 189, Loss: 0.629091
Train - Epoch 0, Batch: 190, Loss: 0.646797
Train - Epoch 0, Batch: 191, Loss: 0.639788
Train - Epoch 0, Batch: 192, Loss: 0.645688
Train - Epoch 0, Batch: 193, Loss: 0.627415
Train - Epoch 0, Batch: 194, Loss: 0.637097
Train - Epoch 0, Batch: 195, Loss: 0.638392
Train - Epoch 0, Batch: 196, Loss: 0.625803
Train - Epoch 0, Batch: 197, Loss: 0.626545
Train - Epoch 0, Batch: 198, Loss: 0.634409
Train - Epoch 0, Batch: 199, Loss: 0.647503
Train - Epoch 0, Batch: 200, Loss: 0.639800
Train - Epoch 0, Batch: 201, Loss: 0.639068
Train - Epoch 0, Batch: 202, Loss: 0.622676
Train - Epoch 0, Batch: 203, Loss: 0.638962
Train - Epoch 0, Batch: 204, Loss: 0.626968
Train - Epoch 0, Batch: 205, Loss: 0.623116
Train - Epoch 0, Batch: 206, Loss: 0.630804
Train - Epoch 0, Batch: 207, Loss: 0.632836
Train - Epoch 0, Batch: 208, Loss: 0.644933
Train - Epoch 0, Batch: 209, Loss: 0.622611
Train - Epoch 0, Batch: 210, Loss: 0.634245
Train - Epoch 0, Batch: 211, Loss: 0.620047
Train - Epoch 0, Batch: 212, Loss: 0.646474
Train - Epoch 0, Batch: 213, Loss: 0.622954
Train - Epoch 0, Batch: 214, Loss: 0.630761
Train - Epoch 0, Batch: 215, Loss: 0.636946
Train - Epoch 0, Batch: 216, Loss: 0.631595
Train - Epoch 0, Batch: 217, Loss: 0.635816
Train - Epoch 0, Batch: 218, Loss: 0.620395
Train - Epoch 0, Batch: 219, Loss: 0.631676
Train - Epoch 0, Batch: 220, Loss: 0.632932
Train - Epoch 0, Batch: 221, Loss: 0.637755
Train - Epoch 0, Batch: 222, Loss: 0.627185
Train - Epoch 0, Batch: 223, Loss: 0.637237
Train - Epoch 0, Batch: 224, Loss: 0.631833
Train - Epoch 0, Batch: 225, Loss: 0.631928
Train - Epoch 0, Batch: 226, Loss: 0.631968
Train - Epoch 0, Batch: 227, Loss: 0.624824
Train - Epoch 0, Batch: 228, Loss: 0.641426
Train - Epoch 0, Batch: 229, Loss: 0.613111
Train - Epoch 0, Batch: 230, Loss: 0.645549
Train - Epoch 0, Batch: 231, Loss: 0.628760
Train - Epoch 0, Batch: 232, Loss: 0.643135
Train - Epoch 0, Batch: 233, Loss: 0.638180
Train - Epoch 0, Batch: 234, Loss: 0.634949
Train - Epoch 0, Batch: 235, Loss: 0.629800
Train - Epoch 0, Batch: 236, Loss: 0.634744
Train - Epoch 0, Batch: 237, Loss: 0.623439
Train - Epoch 0, Batch: 238, Loss: 0.634372
Train - Epoch 0, Batch: 239, Loss: 0.633972
Train - Epoch 0, Batch: 240, Loss: 0.637134
Train - Epoch 0, Batch: 241, Loss: 0.622537
Train - Epoch 0, Batch: 242, Loss: 0.632849
Train - Epoch 0, Batch: 243, Loss: 0.619791
Train - Epoch 0, Batch: 244, Loss: 0.623512
Train - Epoch 0, Batch: 245, Loss: 0.632576
Train - Epoch 0, Batch: 246, Loss: 0.625513
Train - Epoch 0, Batch: 247, Loss: 0.611328
Train - Epoch 0, Batch: 248, Loss: 0.629039
Train - Epoch 0, Batch: 249, Loss: 0.630918
Train - Epoch 0, Batch: 250, Loss: 0.622656
Train - Epoch 0, Batch: 251, Loss: 0.646014
Train - Epoch 0, Batch: 252, Loss: 0.623136
Train - Epoch 0, Batch: 253, Loss: 0.620947
Train - Epoch 0, Batch: 254, Loss: 0.634553
Train - Epoch 0, Batch: 255, Loss: 0.625354
Train - Epoch 0, Batch: 256, Loss: 0.627200
Train - Epoch 0, Batch: 257, Loss: 0.630781
Train - Epoch 0, Batch: 258, Loss: 0.627716
Train - Epoch 0, Batch: 259, Loss: 0.626347
Train - Epoch 0, Batch: 260, Loss: 0.627199
Train - Epoch 0, Batch: 261, Loss: 0.628832
Train - Epoch 0, Batch: 262, Loss: 0.643742
Train - Epoch 0, Batch: 263, Loss: 0.619357
Train - Epoch 0, Batch: 264, Loss: 0.620714
Train - Epoch 0, Batch: 265, Loss: 0.638776
Train - Epoch 0, Batch: 266, Loss: 0.623938
Train - Epoch 0, Batch: 267, Loss: 0.631664
Train - Epoch 0, Batch: 268, Loss: 0.631931
Train - Epoch 0, Batch: 269, Loss: 0.625362
Train - Epoch 0, Batch: 270, Loss: 0.624726
Train - Epoch 0, Batch: 271, Loss: 0.618845
Train - Epoch 0, Batch: 272, Loss: 0.631466
Train - Epoch 0, Batch: 273, Loss: 0.629596
Train - Epoch 0, Batch: 274, Loss: 0.635303
Train - Epoch 0, Batch: 275, Loss: 0.617593
Train - Epoch 0, Batch: 276, Loss: 0.621476
Train - Epoch 0, Batch: 277, Loss: 0.637317
Train - Epoch 0, Batch: 278, Loss: 0.629989
Train - Epoch 0, Batch: 279, Loss: 0.631352
Train - Epoch 0, Batch: 280, Loss: 0.630607
Train - Epoch 0, Batch: 281, Loss: 0.629226
Train - Epoch 0, Batch: 282, Loss: 0.626539
Train - Epoch 0, Batch: 283, Loss: 0.612735
Train - Epoch 0, Batch: 284, Loss: 0.618949
Train - Epoch 0, Batch: 285, Loss: 0.619268
Train - Epoch 0, Batch: 286, Loss: 0.634213
Train - Epoch 0, Batch: 287, Loss: 0.626670
Train - Epoch 0, Batch: 288, Loss: 0.600967
Train - Epoch 0, Batch: 289, Loss: 0.623752
Train - Epoch 0, Batch: 290, Loss: 0.614087
Train - Epoch 0, Batch: 291, Loss: 0.622238
Train - Epoch 0, Batch: 292, Loss: 0.615773
Train - Epoch 0, Batch: 293, Loss: 0.616133
Train - Epoch 0, Batch: 294, Loss: 0.623523
Train - Epoch 0, Batch: 295, Loss: 0.628931
Train - Epoch 0, Batch: 296, Loss: 0.618238
Train - Epoch 0, Batch: 297, Loss: 0.609050
Train - Epoch 0, Batch: 298, Loss: 0.618639
Train - Epoch 0, Batch: 299, Loss: 0.631975
Train - Epoch 0, Batch: 300, Loss: 0.626985
Train - Epoch 0, Batch: 301, Loss: 0.627996
Train - Epoch 0, Batch: 302, Loss: 0.616759
Train - Epoch 0, Batch: 303, Loss: 0.622599
Train - Epoch 0, Batch: 304, Loss: 0.615279
Train - Epoch 0, Batch: 305, Loss: 0.623449
Train - Epoch 0, Batch: 306, Loss: 0.615365
Train - Epoch 0, Batch: 307, Loss: 0.607265
Train - Epoch 0, Batch: 308, Loss: 0.625033
Train - Epoch 0, Batch: 309, Loss: 0.625939
Train - Epoch 0, Batch: 310, Loss: 0.623911
Train - Epoch 0, Batch: 311, Loss: 0.608769
Train - Epoch 0, Batch: 312, Loss: 0.610730
Train - Epoch 0, Batch: 313, Loss: 0.608385
Train - Epoch 0, Batch: 314, Loss: 0.619624
Train - Epoch 0, Batch: 315, Loss: 0.616194
Train - Epoch 0, Batch: 316, Loss: 0.615317
Train - Epoch 0, Batch: 317, Loss: 0.613224
Train - Epoch 0, Batch: 318, Loss: 0.630274
Train - Epoch 0, Batch: 319, Loss: 0.612205
Train - Epoch 0, Batch: 320, Loss: 0.610023
Train - Epoch 0, Batch: 321, Loss: 0.615586
Train - Epoch 0, Batch: 322, Loss: 0.618797
Train - Epoch 0, Batch: 323, Loss: 0.613735
Train - Epoch 0, Batch: 324, Loss: 0.612163
Train - Epoch 0, Batch: 325, Loss: 0.617741
Train - Epoch 0, Batch: 326, Loss: 0.610869
Train - Epoch 0, Batch: 327, Loss: 0.617613
Train - Epoch 0, Batch: 328, Loss: 0.619169
Train - Epoch 0, Batch: 329, Loss: 0.607992
Train - Epoch 0, Batch: 330, Loss: 0.604818
Train - Epoch 0, Batch: 331, Loss: 0.615788
Train - Epoch 0, Batch: 332, Loss: 0.622870
Train - Epoch 0, Batch: 333, Loss: 0.623623
Train - Epoch 0, Batch: 334, Loss: 0.615430
Train - Epoch 0, Batch: 335, Loss: 0.630818
Train - Epoch 0, Batch: 336, Loss: 0.624272
Train - Epoch 0, Batch: 337, Loss: 0.613448
Train - Epoch 0, Batch: 338, Loss: 0.621539
Train - Epoch 0, Batch: 339, Loss: 0.611154
Train - Epoch 0, Batch: 340, Loss: 0.610614
Train - Epoch 0, Batch: 341, Loss: 0.610616
Train - Epoch 0, Batch: 342, Loss: 0.606614
Train - Epoch 0, Batch: 343, Loss: 0.615537
Train - Epoch 0, Batch: 344, Loss: 0.618909
Train - Epoch 0, Batch: 345, Loss: 0.603539
Train - Epoch 0, Batch: 346, Loss: 0.640189
Train - Epoch 0, Batch: 347, Loss: 0.611945
Train - Epoch 0, Batch: 348, Loss: 0.606285
Train - Epoch 0, Batch: 349, Loss: 0.626788
Train - Epoch 0, Batch: 350, Loss: 0.619301
Train - Epoch 0, Batch: 351, Loss: 0.619080
Train - Epoch 0, Batch: 352, Loss: 0.603114
Train - Epoch 0, Batch: 353, Loss: 0.617252
Train - Epoch 0, Batch: 354, Loss: 0.620366
Train - Epoch 0, Batch: 355, Loss: 0.605719
Train - Epoch 0, Batch: 356, Loss: 0.607103
Train - Epoch 0, Batch: 357, Loss: 0.612118
Train - Epoch 0, Batch: 358, Loss: 0.608834
Train - Epoch 0, Batch: 359, Loss: 0.614846
Train - Epoch 0, Batch: 360, Loss: 0.608948
Train - Epoch 0, Batch: 361, Loss: 0.608881
Train - Epoch 0, Batch: 362, Loss: 0.619295
Train - Epoch 0, Batch: 363, Loss: 0.602903
Train - Epoch 0, Batch: 364, Loss: 0.603151
Train - Epoch 0, Batch: 365, Loss: 0.605213
Train - Epoch 0, Batch: 366, Loss: 0.611627
Train - Epoch 0, Batch: 367, Loss: 0.610051
Train - Epoch 0, Batch: 368, Loss: 0.615792
Train - Epoch 0, Batch: 369, Loss: 0.616705
Train - Epoch 0, Batch: 370, Loss: 0.615845
Train - Epoch 0, Batch: 371, Loss: 0.619968
Train - Epoch 0, Batch: 372, Loss: 0.608468
Train - Epoch 0, Batch: 373, Loss: 0.602297
Train - Epoch 0, Batch: 374, Loss: 0.596083
Train - Epoch 0, Batch: 375, Loss: 0.600529
Train - Epoch 0, Batch: 376, Loss: 0.614569
Train - Epoch 0, Batch: 377, Loss: 0.617750
Train - Epoch 0, Batch: 378, Loss: 0.626244
Train - Epoch 0, Batch: 379, Loss: 0.606859
Train - Epoch 0, Batch: 380, Loss: 0.606856
Train - Epoch 0, Batch: 381, Loss: 0.618647
Train - Epoch 0, Batch: 382, Loss: 0.596566
Train - Epoch 0, Batch: 383, Loss: 0.619697
Train - Epoch 0, Batch: 384, Loss: 0.611580
Train - Epoch 0, Batch: 385, Loss: 0.608757
Train - Epoch 0, Batch: 386, Loss: 0.610257
Train - Epoch 0, Batch: 387, Loss: 0.600032
Train - Epoch 0, Batch: 388, Loss: 0.630321
Train - Epoch 0, Batch: 389, Loss: 0.625589
Train - Epoch 0, Batch: 390, Loss: 0.610510
Train - Epoch 0, Batch: 391, Loss: 0.613758
Train - Epoch 0, Batch: 392, Loss: 0.615350
Train - Epoch 0, Batch: 393, Loss: 0.605828
Train - Epoch 0, Batch: 394, Loss: 0.606167
Train - Epoch 0, Batch: 395, Loss: 0.609449
Train - Epoch 0, Batch: 396, Loss: 0.614139
Train - Epoch 0, Batch: 397, Loss: 0.630367
Train - Epoch 0, Batch: 398, Loss: 0.607775
Train - Epoch 0, Batch: 399, Loss: 0.610896
Train - Epoch 0, Batch: 400, Loss: 0.599913
Train - Epoch 0, Batch: 401, Loss: 0.613245
Train - Epoch 0, Batch: 402, Loss: 0.614908
Train - Epoch 0, Batch: 403, Loss: 0.596080
Train - Epoch 0, Batch: 404, Loss: 0.609839
Train - Epoch 0, Batch: 405, Loss: 0.613782
Train - Epoch 0, Batch: 406, Loss: 0.633616
Train - Epoch 0, Batch: 407, Loss: 0.617161
Train - Epoch 0, Batch: 408, Loss: 0.613814
Train - Epoch 0, Batch: 409, Loss: 0.621864
Train - Epoch 0, Batch: 410, Loss: 0.611585
Train - Epoch 0, Batch: 411, Loss: 0.606351
Train - Epoch 0, Batch: 412, Loss: 0.602174
Train - Epoch 0, Batch: 413, Loss: 0.616033
Train - Epoch 0, Batch: 414, Loss: 0.615893
Train - Epoch 0, Batch: 415, Loss: 0.611390
Train - Epoch 0, Batch: 416, Loss: 0.613286
Train - Epoch 0, Batch: 417, Loss: 0.605887
Train - Epoch 0, Batch: 418, Loss: 0.610760
Train - Epoch 0, Batch: 419, Loss: 0.597770
Train - Epoch 0, Batch: 420, Loss: 0.613123
Train - Epoch 0, Batch: 421, Loss: 0.605278
Train - Epoch 0, Batch: 422, Loss: 0.613827
Train - Epoch 0, Batch: 423, Loss: 0.608083
Train - Epoch 0, Batch: 424, Loss: 0.587444
Train - Epoch 0, Batch: 425, Loss: 0.620053
Train - Epoch 0, Batch: 426, Loss: 0.613821
Train - Epoch 0, Batch: 427, Loss: 0.614099
Train - Epoch 0, Batch: 428, Loss: 0.601692
Train - Epoch 0, Batch: 429, Loss: 0.584165
Train - Epoch 0, Batch: 430, Loss: 0.605260
Train - Epoch 0, Batch: 431, Loss: 0.606948
Train - Epoch 0, Batch: 432, Loss: 0.612445
Train - Epoch 0, Batch: 433, Loss: 0.606945
Train - Epoch 0, Batch: 434, Loss: 0.605455
Train - Epoch 0, Batch: 435, Loss: 0.606252
Train - Epoch 0, Batch: 436, Loss: 0.598550
Train - Epoch 0, Batch: 437, Loss: 0.619913
Train - Epoch 0, Batch: 438, Loss: 0.630036
Train - Epoch 0, Batch: 439, Loss: 0.612209
Train - Epoch 0, Batch: 440, Loss: 0.610900
Train - Epoch 0, Batch: 441, Loss: 0.628879
Train - Epoch 0, Batch: 442, Loss: 0.611101
Train - Epoch 0, Batch: 443, Loss: 0.624395
Train - Epoch 0, Batch: 444, Loss: 0.591900
Train - Epoch 0, Batch: 445, Loss: 0.611316
Train - Epoch 0, Batch: 446, Loss: 0.596674
Train - Epoch 0, Batch: 447, Loss: 0.602853
Train - Epoch 0, Batch: 448, Loss: 0.609122
Train - Epoch 0, Batch: 449, Loss: 0.601352
Train - Epoch 0, Batch: 450, Loss: 0.619826
Train - Epoch 0, Batch: 451, Loss: 0.585448
Train - Epoch 0, Batch: 452, Loss: 0.607843
Train - Epoch 0, Batch: 453, Loss: 0.608028
Train - Epoch 0, Batch: 454, Loss: 0.594004
Train - Epoch 0, Batch: 455, Loss: 0.611157
Train - Epoch 0, Batch: 456, Loss: 0.597065
Train - Epoch 0, Batch: 457, Loss: 0.636051
Train - Epoch 0, Batch: 458, Loss: 0.577391
Train - Epoch 0, Batch: 459, Loss: 0.614756
Train - Epoch 0, Batch: 460, Loss: 0.595815
Train - Epoch 0, Batch: 461, Loss: 0.600604
Train - Epoch 0, Batch: 462, Loss: 0.625207
Train - Epoch 0, Batch: 463, Loss: 0.612984
Train - Epoch 0, Batch: 464, Loss: 0.590694
Train - Epoch 0, Batch: 465, Loss: 0.621071
Train - Epoch 0, Batch: 466, Loss: 0.600185
Train - Epoch 0, Batch: 467, Loss: 0.595839
Train - Epoch 0, Batch: 468, Loss: 0.611209
Train - Epoch 0, Batch: 469, Loss: 0.604116
Train - Epoch 0, Batch: 470, Loss: 0.618621
Train - Epoch 0, Batch: 471, Loss: 0.601575
Train - Epoch 0, Batch: 472, Loss: 0.588381
Train - Epoch 0, Batch: 473, Loss: 0.597615
Train - Epoch 0, Batch: 474, Loss: 0.605694
Train - Epoch 0, Batch: 475, Loss: 0.589938
Train - Epoch 0, Batch: 476, Loss: 0.593299
Train - Epoch 0, Batch: 477, Loss: 0.611222
Train - Epoch 0, Batch: 478, Loss: 0.591262
Train - Epoch 0, Batch: 479, Loss: 0.602495
Train - Epoch 0, Batch: 480, Loss: 0.612516
Train - Epoch 0, Batch: 481, Loss: 0.600573
Train - Epoch 0, Batch: 482, Loss: 0.613234
Train - Epoch 0, Batch: 483, Loss: 0.600120
Train - Epoch 0, Batch: 484, Loss: 0.612886
Train - Epoch 0, Batch: 485, Loss: 0.603880
Train - Epoch 0, Batch: 486, Loss: 0.602656
Train - Epoch 0, Batch: 487, Loss: 0.611399
Train - Epoch 0, Batch: 488, Loss: 0.606109
Train - Epoch 0, Batch: 489, Loss: 0.615659
Train - Epoch 0, Batch: 490, Loss: 0.594776
Train - Epoch 0, Batch: 491, Loss: 0.617957
Train - Epoch 0, Batch: 492, Loss: 0.601146
Train - Epoch 0, Batch: 493, Loss: 0.604640
Train - Epoch 0, Batch: 494, Loss: 0.607032
Train - Epoch 0, Batch: 495, Loss: 0.612208
Train - Epoch 0, Batch: 496, Loss: 0.620236
Train - Epoch 0, Batch: 497, Loss: 0.618572
Train - Epoch 0, Batch: 498, Loss: 0.605036
Train - Epoch 0, Batch: 499, Loss: 0.609260
Train - Epoch 0, Batch: 500, Loss: 0.616952
Train - Epoch 0, Batch: 501, Loss: 0.609950
Train - Epoch 0, Batch: 502, Loss: 0.600473
Train - Epoch 0, Batch: 503, Loss: 0.595982
Train - Epoch 0, Batch: 504, Loss: 0.598242
Train - Epoch 0, Batch: 505, Loss: 0.589352
Train - Epoch 0, Batch: 506, Loss: 0.600146
Train - Epoch 0, Batch: 507, Loss: 0.595233
Train - Epoch 0, Batch: 508, Loss: 0.597033
Train - Epoch 0, Batch: 509, Loss: 0.601437
Train - Epoch 0, Batch: 510, Loss: 0.605253
Train - Epoch 0, Batch: 511, Loss: 0.594774
Train - Epoch 0, Batch: 512, Loss: 0.590396
Train - Epoch 0, Batch: 513, Loss: 0.595430
Train - Epoch 0, Batch: 514, Loss: 0.601330
Train - Epoch 0, Batch: 515, Loss: 0.609377
Train - Epoch 0, Batch: 516, Loss: 0.601190
Train - Epoch 0, Batch: 517, Loss: 0.602025
Train - Epoch 0, Batch: 518, Loss: 0.616366
Train - Epoch 0, Batch: 519, Loss: 0.596409
Train - Epoch 0, Batch: 520, Loss: 0.600735
Train - Epoch 0, Batch: 521, Loss: 0.587165
Train - Epoch 0, Batch: 522, Loss: 0.599417
Train - Epoch 0, Batch: 523, Loss: 0.611706
Train - Epoch 0, Batch: 524, Loss: 0.593905
Train - Epoch 0, Batch: 525, Loss: 0.611629
Train - Epoch 0, Batch: 526, Loss: 0.602587
Train - Epoch 0, Batch: 527, Loss: 0.610115
Train - Epoch 0, Batch: 528, Loss: 0.590284
Train - Epoch 0, Batch: 529, Loss: 0.595511
Train - Epoch 0, Batch: 530, Loss: 0.591982
Train - Epoch 0, Batch: 531, Loss: 0.595735
Train - Epoch 0, Batch: 532, Loss: 0.598945
Train - Epoch 0, Batch: 533, Loss: 0.590240
Train - Epoch 0, Batch: 534, Loss: 0.592547
Train - Epoch 0, Batch: 535, Loss: 0.608737
Train - Epoch 0, Batch: 536, Loss: 0.597814
Train - Epoch 0, Batch: 537, Loss: 0.593133
Train - Epoch 0, Batch: 538, Loss: 0.588152
Train - Epoch 0, Batch: 539, Loss: 0.586004
Train - Epoch 0, Batch: 540, Loss: 0.596782
Train - Epoch 0, Batch: 541, Loss: 0.581768
Train - Epoch 0, Batch: 542, Loss: 0.599691
Train - Epoch 0, Batch: 543, Loss: 0.597774
Train - Epoch 0, Batch: 544, Loss: 0.601743
Train - Epoch 0, Batch: 545, Loss: 0.606864
Train - Epoch 0, Batch: 546, Loss: 0.606579
Train - Epoch 0, Batch: 547, Loss: 0.594953
Train - Epoch 0, Batch: 548, Loss: 0.580026
Train - Epoch 0, Batch: 549, Loss: 0.605717
Train - Epoch 0, Batch: 550, Loss: 0.612586
Train - Epoch 0, Batch: 551, Loss: 0.592867
Train - Epoch 0, Batch: 552, Loss: 0.606363
Train - Epoch 0, Batch: 553, Loss: 0.597228
Train - Epoch 0, Batch: 554, Loss: 0.606362
Train - Epoch 0, Batch: 555, Loss: 0.598720
Train - Epoch 0, Batch: 556, Loss: 0.593574
Train - Epoch 0, Batch: 557, Loss: 0.619537
Train - Epoch 0, Batch: 558, Loss: 0.607478
Train - Epoch 0, Batch: 559, Loss: 0.593872
Train - Epoch 0, Batch: 560, Loss: 0.596030
Train - Epoch 0, Batch: 561, Loss: 0.603556
Train - Epoch 0, Batch: 562, Loss: 0.611081
Train - Epoch 0, Batch: 563, Loss: 0.571952
Train - Epoch 0, Batch: 564, Loss: 0.580877
Train - Epoch 0, Batch: 565, Loss: 0.595182
Train - Epoch 0, Batch: 566, Loss: 0.604249
Train - Epoch 0, Batch: 567, Loss: 0.606100
Train - Epoch 0, Batch: 568, Loss: 0.587959
Train - Epoch 0, Batch: 569, Loss: 0.599453
Train - Epoch 0, Batch: 570, Loss: 0.608350
Train - Epoch 0, Batch: 571, Loss: 0.604859
Train - Epoch 0, Batch: 572, Loss: 0.576437
Train - Epoch 0, Batch: 573, Loss: 0.592516
Train - Epoch 0, Batch: 574, Loss: 0.599456
Train - Epoch 0, Batch: 575, Loss: 0.587318
Train - Epoch 0, Batch: 576, Loss: 0.602576
Train - Epoch 0, Batch: 577, Loss: 0.601005
Train - Epoch 0, Batch: 578, Loss: 0.595202
Train - Epoch 0, Batch: 579, Loss: 0.607077
Train - Epoch 0, Batch: 580, Loss: 0.611038
Train - Epoch 0, Batch: 581, Loss: 0.584984
Train - Epoch 0, Batch: 582, Loss: 0.603305
Train - Epoch 0, Batch: 583, Loss: 0.595246
Train - Epoch 0, Batch: 584, Loss: 0.601821
Train - Epoch 0, Batch: 585, Loss: 0.584369
Train - Epoch 0, Batch: 586, Loss: 0.597457
Train - Epoch 0, Batch: 587, Loss: 0.600237
Train - Epoch 0, Batch: 588, Loss: 0.599977
Train - Epoch 0, Batch: 589, Loss: 0.589894
Train - Epoch 0, Batch: 590, Loss: 0.607641
Train - Epoch 0, Batch: 591, Loss: 0.592928
Train - Epoch 0, Batch: 592, Loss: 0.604329
Train - Epoch 0, Batch: 593, Loss: 0.576837
Train - Epoch 0, Batch: 594, Loss: 0.576387
Train - Epoch 0, Batch: 595, Loss: 0.611435
Train - Epoch 0, Batch: 596, Loss: 0.591179
Train - Epoch 0, Batch: 597, Loss: 0.602557
Train - Epoch 0, Batch: 598, Loss: 0.594258
Train - Epoch 0, Batch: 599, Loss: 0.588436
Train - Epoch 0, Batch: 600, Loss: 0.585287
Train - Epoch 0, Batch: 601, Loss: 0.589568
Train - Epoch 0, Batch: 602, Loss: 0.608747
Train - Epoch 0, Batch: 603, Loss: 0.594752
Train - Epoch 0, Batch: 604, Loss: 0.575571
Train - Epoch 0, Batch: 605, Loss: 0.605236
Train - Epoch 0, Batch: 606, Loss: 0.591632
Train - Epoch 0, Batch: 607, Loss: 0.593265
Train - Epoch 0, Batch: 608, Loss: 0.622103
Train - Epoch 0, Batch: 609, Loss: 0.580810
Train - Epoch 0, Batch: 610, Loss: 0.603141
Train - Epoch 0, Batch: 611, Loss: 0.605966
Train - Epoch 0, Batch: 612, Loss: 0.601312
Train - Epoch 0, Batch: 613, Loss: 0.587743
Train - Epoch 0, Batch: 614, Loss: 0.614707
Train - Epoch 0, Batch: 615, Loss: 0.596585
Train - Epoch 0, Batch: 616, Loss: 0.628711
Train - Epoch 0, Batch: 617, Loss: 0.602001
Train - Epoch 0, Batch: 618, Loss: 0.598610
Train - Epoch 0, Batch: 619, Loss: 0.588468
Train - Epoch 0, Batch: 620, Loss: 0.611690
Train - Epoch 0, Batch: 621, Loss: 0.582554
Train - Epoch 0, Batch: 622, Loss: 0.583559
Train - Epoch 0, Batch: 623, Loss: 0.582890
Train - Epoch 0, Batch: 624, Loss: 0.601197
Train - Epoch 0, Batch: 625, Loss: 0.598951
Train - Epoch 0, Batch: 626, Loss: 0.601029
Train - Epoch 0, Batch: 627, Loss: 0.601995
Train - Epoch 0, Batch: 628, Loss: 0.582284
Train - Epoch 0, Batch: 629, Loss: 0.573430
Train - Epoch 0, Batch: 630, Loss: 0.611466
Train - Epoch 0, Batch: 631, Loss: 0.589977
Train - Epoch 0, Batch: 632, Loss: 0.603532
Train - Epoch 0, Batch: 633, Loss: 0.602616
Train - Epoch 0, Batch: 634, Loss: 0.599188
Train - Epoch 0, Batch: 635, Loss: 0.588853
Train - Epoch 0, Batch: 636, Loss: 0.583837
Train - Epoch 0, Batch: 637, Loss: 0.580937
Train - Epoch 0, Batch: 638, Loss: 0.603065
Train - Epoch 0, Batch: 639, Loss: 0.594100
Train - Epoch 0, Batch: 640, Loss: 0.591327
Train - Epoch 0, Batch: 641, Loss: 0.577796
Train - Epoch 0, Batch: 642, Loss: 0.590106
Train - Epoch 0, Batch: 643, Loss: 0.571195
Train - Epoch 0, Batch: 644, Loss: 0.575134
Train - Epoch 0, Batch: 645, Loss: 0.598482
Train - Epoch 0, Batch: 646, Loss: 0.592468
Train - Epoch 0, Batch: 647, Loss: 0.597488
Train - Epoch 0, Batch: 648, Loss: 0.608646
Train - Epoch 0, Batch: 649, Loss: 0.589599
Train - Epoch 0, Batch: 650, Loss: 0.598449
Train - Epoch 0, Batch: 651, Loss: 0.593676
Train - Epoch 0, Batch: 652, Loss: 0.577822
Train - Epoch 0, Batch: 653, Loss: 0.608436
Train - Epoch 0, Batch: 654, Loss: 0.626687
Train - Epoch 0, Batch: 655, Loss: 0.589506
Train - Epoch 0, Batch: 656, Loss: 0.598065
Train - Epoch 0, Batch: 657, Loss: 0.603964
Train - Epoch 0, Batch: 658, Loss: 0.592403
Train - Epoch 0, Batch: 659, Loss: 0.591774
Train - Epoch 0, Batch: 660, Loss: 0.598868
Train - Epoch 0, Batch: 661, Loss: 0.595732
Train - Epoch 0, Batch: 662, Loss: 0.588778
Train - Epoch 0, Batch: 663, Loss: 0.599265
Train - Epoch 0, Batch: 664, Loss: 0.582163
Train - Epoch 0, Batch: 665, Loss: 0.605045
Train - Epoch 0, Batch: 666, Loss: 0.598129
Train - Epoch 0, Batch: 667, Loss: 0.573485
Train - Epoch 0, Batch: 668, Loss: 0.596090
Train - Epoch 0, Batch: 669, Loss: 0.597583
Train - Epoch 0, Batch: 670, Loss: 0.574807
Train - Epoch 0, Batch: 671, Loss: 0.583838
Train - Epoch 0, Batch: 672, Loss: 0.579494
Train - Epoch 0, Batch: 673, Loss: 0.607726
Train - Epoch 0, Batch: 674, Loss: 0.588515
Train - Epoch 0, Batch: 675, Loss: 0.587499
Train - Epoch 0, Batch: 676, Loss: 0.595089
Train - Epoch 0, Batch: 677, Loss: 0.601636
Train - Epoch 0, Batch: 678, Loss: 0.602693
Train - Epoch 0, Batch: 679, Loss: 0.567569
Train - Epoch 0, Batch: 680, Loss: 0.597101
Train - Epoch 0, Batch: 681, Loss: 0.584318
Train - Epoch 0, Batch: 682, Loss: 0.591437
Train - Epoch 0, Batch: 683, Loss: 0.606071
Train - Epoch 0, Batch: 684, Loss: 0.575380
Train - Epoch 0, Batch: 685, Loss: 0.594217
Train - Epoch 0, Batch: 686, Loss: 0.627252
Train - Epoch 0, Batch: 687, Loss: 0.616311
Train - Epoch 0, Batch: 688, Loss: 0.612281
Train - Epoch 0, Batch: 689, Loss: 0.599761
Train - Epoch 0, Batch: 690, Loss: 0.597349
Train - Epoch 0, Batch: 691, Loss: 0.595975
Train - Epoch 0, Batch: 692, Loss: 0.581015
Train - Epoch 0, Batch: 693, Loss: 0.592312
Train - Epoch 0, Batch: 694, Loss: 0.581206
Train - Epoch 0, Batch: 695, Loss: 0.583942
Train - Epoch 0, Batch: 696, Loss: 0.575507
Train - Epoch 0, Batch: 697, Loss: 0.591239
Train - Epoch 0, Batch: 698, Loss: 0.575538
Train - Epoch 0, Batch: 699, Loss: 0.614432
Train - Epoch 0, Batch: 700, Loss: 0.591693
Train - Epoch 0, Batch: 701, Loss: 0.599285
Train - Epoch 0, Batch: 702, Loss: 0.614709
Train - Epoch 0, Batch: 703, Loss: 0.616411
Train - Epoch 0, Batch: 704, Loss: 0.598122
Train - Epoch 0, Batch: 705, Loss: 0.591414
Train - Epoch 0, Batch: 706, Loss: 0.584664
Train - Epoch 0, Batch: 707, Loss: 0.588486
Train - Epoch 0, Batch: 708, Loss: 0.612260
Train - Epoch 0, Batch: 709, Loss: 0.606966
Train - Epoch 0, Batch: 710, Loss: 0.579121
Train - Epoch 0, Batch: 711, Loss: 0.581523
Train - Epoch 0, Batch: 712, Loss: 0.574560
Train - Epoch 0, Batch: 713, Loss: 0.592794
Train - Epoch 0, Batch: 714, Loss: 0.585457
Train - Epoch 0, Batch: 715, Loss: 0.581440
Train - Epoch 0, Batch: 716, Loss: 0.580733
Train - Epoch 0, Batch: 717, Loss: 0.593589
Train - Epoch 0, Batch: 718, Loss: 0.589409
Train - Epoch 0, Batch: 719, Loss: 0.585541
Train - Epoch 0, Batch: 720, Loss: 0.591060
Train - Epoch 0, Batch: 721, Loss: 0.586309
Train - Epoch 0, Batch: 722, Loss: 0.610594
Train - Epoch 0, Batch: 723, Loss: 0.579436
Train - Epoch 0, Batch: 724, Loss: 0.599001
Train - Epoch 0, Batch: 725, Loss: 0.591569
Train - Epoch 0, Batch: 726, Loss: 0.572796
Train - Epoch 0, Batch: 727, Loss: 0.575198
Train - Epoch 0, Batch: 728, Loss: 0.588104
Train - Epoch 0, Batch: 729, Loss: 0.591346
Train - Epoch 0, Batch: 730, Loss: 0.589586
Train - Epoch 0, Batch: 731, Loss: 0.579286
Train - Epoch 0, Batch: 732, Loss: 0.600214
Train - Epoch 0, Batch: 733, Loss: 0.571272
Train - Epoch 0, Batch: 734, Loss: 0.603370
Train - Epoch 0, Batch: 735, Loss: 0.596743
Train - Epoch 0, Batch: 736, Loss: 0.596236
Train - Epoch 0, Batch: 737, Loss: 0.605040
Train - Epoch 0, Batch: 738, Loss: 0.576091
Train - Epoch 0, Batch: 739, Loss: 0.575065
Train - Epoch 0, Batch: 740, Loss: 0.579384
Train - Epoch 0, Batch: 741, Loss: 0.586832
Train - Epoch 0, Batch: 742, Loss: 0.582892
Train - Epoch 0, Batch: 743, Loss: 0.597965
Train - Epoch 0, Batch: 744, Loss: 0.584450
Train - Epoch 0, Batch: 745, Loss: 0.607869
Train - Epoch 0, Batch: 746, Loss: 0.607342
Train - Epoch 0, Batch: 747, Loss: 0.569322
Train - Epoch 0, Batch: 748, Loss: 0.586537
Train - Epoch 0, Batch: 749, Loss: 0.586399
Train - Epoch 0, Batch: 750, Loss: 0.587283
Train - Epoch 0, Batch: 751, Loss: 0.590361
Train - Epoch 0, Batch: 752, Loss: 0.597186
Train - Epoch 0, Batch: 753, Loss: 0.612679
Train - Epoch 0, Batch: 754, Loss: 0.576934
Train - Epoch 0, Batch: 755, Loss: 0.580832
Train - Epoch 0, Batch: 756, Loss: 0.597620
Train - Epoch 0, Batch: 757, Loss: 0.596755
Train - Epoch 0, Batch: 758, Loss: 0.563072
Train - Epoch 0, Batch: 759, Loss: 0.593676
Train - Epoch 0, Batch: 760, Loss: 0.599581
Train - Epoch 0, Batch: 761, Loss: 0.612614
Train - Epoch 0, Batch: 762, Loss: 0.570988
Train - Epoch 0, Batch: 763, Loss: 0.577670
Train - Epoch 0, Batch: 764, Loss: 0.592920
Train - Epoch 0, Batch: 765, Loss: 0.580695
Train - Epoch 0, Batch: 766, Loss: 0.602322
Train - Epoch 0, Batch: 767, Loss: 0.579359
Train - Epoch 0, Batch: 768, Loss: 0.577708
Train - Epoch 0, Batch: 769, Loss: 0.582748
Train - Epoch 0, Batch: 770, Loss: 0.573849
Train - Epoch 0, Batch: 771, Loss: 0.591121
Train - Epoch 0, Batch: 772, Loss: 0.588711
Train - Epoch 0, Batch: 773, Loss: 0.592942
Train - Epoch 0, Batch: 774, Loss: 0.602513
Train - Epoch 0, Batch: 775, Loss: 0.585805
Train - Epoch 0, Batch: 776, Loss: 0.578645
Train - Epoch 0, Batch: 777, Loss: 0.582159
Train - Epoch 0, Batch: 778, Loss: 0.590127
Train - Epoch 0, Batch: 779, Loss: 0.574062
Train - Epoch 0, Batch: 780, Loss: 0.594100
Train - Epoch 0, Batch: 781, Loss: 0.586054
Train - Epoch 0, Batch: 782, Loss: 0.598093
Train - Epoch 0, Batch: 783, Loss: 0.609413
Train - Epoch 0, Batch: 784, Loss: 0.605573
Train - Epoch 0, Batch: 785, Loss: 0.589673
Train - Epoch 0, Batch: 786, Loss: 0.589619
Train - Epoch 0, Batch: 787, Loss: 0.590967
Train - Epoch 0, Batch: 788, Loss: 0.575567
Train - Epoch 0, Batch: 789, Loss: 0.590456
Train - Epoch 0, Batch: 790, Loss: 0.594003
Train - Epoch 0, Batch: 791, Loss: 0.595604
Train - Epoch 0, Batch: 792, Loss: 0.586887
Train - Epoch 0, Batch: 793, Loss: 0.592918
Train - Epoch 0, Batch: 794, Loss: 0.593018
Train - Epoch 0, Batch: 795, Loss: 0.574764
Train - Epoch 0, Batch: 796, Loss: 0.566785
Train - Epoch 0, Batch: 797, Loss: 0.571664
Train - Epoch 0, Batch: 798, Loss: 0.556875
Train - Epoch 0, Batch: 799, Loss: 0.593944
Train - Epoch 0, Batch: 800, Loss: 0.575541
Train - Epoch 0, Batch: 801, Loss: 0.589784
Train - Epoch 0, Batch: 802, Loss: 0.607314
Train - Epoch 0, Batch: 803, Loss: 0.581461
Train - Epoch 0, Batch: 804, Loss: 0.587581
Train - Epoch 0, Batch: 805, Loss: 0.593825
Train - Epoch 0, Batch: 806, Loss: 0.602392
Train - Epoch 0, Batch: 807, Loss: 0.600990
Train - Epoch 0, Batch: 808, Loss: 0.569378
Train - Epoch 0, Batch: 809, Loss: 0.577816
Train - Epoch 0, Batch: 810, Loss: 0.599532
Train - Epoch 0, Batch: 811, Loss: 0.598392
Train - Epoch 0, Batch: 812, Loss: 0.583816
Train - Epoch 0, Batch: 813, Loss: 0.586931
Train - Epoch 0, Batch: 814, Loss: 0.585089
Train - Epoch 0, Batch: 815, Loss: 0.556743
Train - Epoch 0, Batch: 816, Loss: 0.595997
Train - Epoch 0, Batch: 817, Loss: 0.590578
Train - Epoch 0, Batch: 818, Loss: 0.588664
Train - Epoch 0, Batch: 819, Loss: 0.597587
Train - Epoch 0, Batch: 820, Loss: 0.573924
Train - Epoch 0, Batch: 821, Loss: 0.583735
Train - Epoch 0, Batch: 822, Loss: 0.590377
Train - Epoch 0, Batch: 823, Loss: 0.571316
Train - Epoch 0, Batch: 824, Loss: 0.594330
Train - Epoch 0, Batch: 825, Loss: 0.610948
Train - Epoch 0, Batch: 826, Loss: 0.566610
Train - Epoch 0, Batch: 827, Loss: 0.569970
Train - Epoch 0, Batch: 828, Loss: 0.601372
Train - Epoch 0, Batch: 829, Loss: 0.569518
Train - Epoch 0, Batch: 830, Loss: 0.598644
Train - Epoch 0, Batch: 831, Loss: 0.595299
Train - Epoch 0, Batch: 832, Loss: 0.594176
Train - Epoch 0, Batch: 833, Loss: 0.571343
Train - Epoch 0, Batch: 834, Loss: 0.596681
Train - Epoch 0, Batch: 835, Loss: 0.589358
Train - Epoch 0, Batch: 836, Loss: 0.582800
Train - Epoch 0, Batch: 837, Loss: 0.580303
Train - Epoch 0, Batch: 838, Loss: 0.575429
Train - Epoch 0, Batch: 839, Loss: 0.597577
Train - Epoch 0, Batch: 840, Loss: 0.587220
Train - Epoch 0, Batch: 841, Loss: 0.588783
Train - Epoch 0, Batch: 842, Loss: 0.600701
Train - Epoch 0, Batch: 843, Loss: 0.571931
Train - Epoch 0, Batch: 844, Loss: 0.579135
Train - Epoch 0, Batch: 845, Loss: 0.592075
Train - Epoch 0, Batch: 846, Loss: 0.574883
Train - Epoch 0, Batch: 847, Loss: 0.586780
Train - Epoch 0, Batch: 848, Loss: 0.580093
Train - Epoch 0, Batch: 849, Loss: 0.570148
Train - Epoch 0, Batch: 850, Loss: 0.589321
Train - Epoch 0, Batch: 851, Loss: 0.581811
Train - Epoch 0, Batch: 852, Loss: 0.589207
Train - Epoch 0, Batch: 853, Loss: 0.600608
Train - Epoch 0, Batch: 854, Loss: 0.605553
Train - Epoch 0, Batch: 855, Loss: 0.585604
Train - Epoch 0, Batch: 856, Loss: 0.585088
Train - Epoch 0, Batch: 857, Loss: 0.575566
Train - Epoch 0, Batch: 858, Loss: 0.592452
Train - Epoch 0, Batch: 859, Loss: 0.590542
Train - Epoch 0, Batch: 860, Loss: 0.588517
Train - Epoch 0, Batch: 861, Loss: 0.564461
Train - Epoch 0, Batch: 862, Loss: 0.564037
Train - Epoch 0, Batch: 863, Loss: 0.580477
Train - Epoch 0, Batch: 864, Loss: 0.591124
Train - Epoch 0, Batch: 865, Loss: 0.581314
Train - Epoch 0, Batch: 866, Loss: 0.589056
Train - Epoch 0, Batch: 867, Loss: 0.577716
Train - Epoch 0, Batch: 868, Loss: 0.575236
Train - Epoch 0, Batch: 869, Loss: 0.591492
Train - Epoch 0, Batch: 870, Loss: 0.583830
Train - Epoch 0, Batch: 871, Loss: 0.578775
Train - Epoch 0, Batch: 872, Loss: 0.607374
Train - Epoch 0, Batch: 873, Loss: 0.566021
Train - Epoch 0, Batch: 874, Loss: 0.603290
Train - Epoch 0, Batch: 875, Loss: 0.585914
Train - Epoch 0, Batch: 876, Loss: 0.609926
Train - Epoch 0, Batch: 877, Loss: 0.592984
Train - Epoch 0, Batch: 878, Loss: 0.577139
Train - Epoch 0, Batch: 879, Loss: 0.571525
Train - Epoch 0, Batch: 880, Loss: 0.587618
Train - Epoch 0, Batch: 881, Loss: 0.582144
Train - Epoch 0, Batch: 882, Loss: 0.570520
Train - Epoch 0, Batch: 883, Loss: 0.588122
Train - Epoch 0, Batch: 884, Loss: 0.600189
Train - Epoch 0, Batch: 885, Loss: 0.558608
Train - Epoch 0, Batch: 886, Loss: 0.583833
Train - Epoch 0, Batch: 887, Loss: 0.608476
Train - Epoch 0, Batch: 888, Loss: 0.594466
Train - Epoch 0, Batch: 889, Loss: 0.583793
Train - Epoch 0, Batch: 890, Loss: 0.592804
Train - Epoch 0, Batch: 891, Loss: 0.556062
Train - Epoch 0, Batch: 892, Loss: 0.588954
Train - Epoch 0, Batch: 893, Loss: 0.602204
Train - Epoch 0, Batch: 894, Loss: 0.596655
Train - Epoch 0, Batch: 895, Loss: 0.586453
Train - Epoch 0, Batch: 896, Loss: 0.572238
Train - Epoch 0, Batch: 897, Loss: 0.591237
Train - Epoch 0, Batch: 898, Loss: 0.578435
Train - Epoch 0, Batch: 899, Loss: 0.603528
Train - Epoch 0, Batch: 900, Loss: 0.557911
Train - Epoch 0, Batch: 901, Loss: 0.582033
Train - Epoch 0, Batch: 902, Loss: 0.588376
Train - Epoch 0, Batch: 903, Loss: 0.575051
Train - Epoch 0, Batch: 904, Loss: 0.585556
Train - Epoch 0, Batch: 905, Loss: 0.575902
Train - Epoch 0, Batch: 906, Loss: 0.629482
Train - Epoch 0, Batch: 907, Loss: 0.569666
Train - Epoch 0, Batch: 908, Loss: 0.585318
Train - Epoch 0, Batch: 909, Loss: 0.575736
Train - Epoch 0, Batch: 910, Loss: 0.577229
Train - Epoch 0, Batch: 911, Loss: 0.583777
Train - Epoch 0, Batch: 912, Loss: 0.563413
Train - Epoch 0, Batch: 913, Loss: 0.585664
Train - Epoch 0, Batch: 914, Loss: 0.597923
Train - Epoch 0, Batch: 915, Loss: 0.586371
Train - Epoch 0, Batch: 916, Loss: 0.588805
Train - Epoch 0, Batch: 917, Loss: 0.569321
Train - Epoch 0, Batch: 918, Loss: 0.579665
Train - Epoch 0, Batch: 919, Loss: 0.573249
Train - Epoch 0, Batch: 920, Loss: 0.599825
Train - Epoch 0, Batch: 921, Loss: 0.594043
Train - Epoch 0, Batch: 922, Loss: 0.571049
Train - Epoch 0, Batch: 923, Loss: 0.597476
Train - Epoch 0, Batch: 924, Loss: 0.583491
Train - Epoch 0, Batch: 925, Loss: 0.581404
Train - Epoch 0, Batch: 926, Loss: 0.596260
Train - Epoch 0, Batch: 927, Loss: 0.565318
Train - Epoch 0, Batch: 928, Loss: 0.560667
Train - Epoch 0, Batch: 929, Loss: 0.570660
Train - Epoch 0, Batch: 930, Loss: 0.569189
Train - Epoch 0, Batch: 931, Loss: 0.593666
Train - Epoch 0, Batch: 932, Loss: 0.579753
Train - Epoch 0, Batch: 933, Loss: 0.585374
Train - Epoch 0, Batch: 934, Loss: 0.580483
Train - Epoch 0, Batch: 935, Loss: 0.575577
Train - Epoch 0, Batch: 936, Loss: 0.582371
Train - Epoch 0, Batch: 937, Loss: 0.585901
Train - Epoch 0, Batch: 938, Loss: 0.583287
Train - Epoch 0, Batch: 939, Loss: 0.618019
Train - Epoch 0, Batch: 940, Loss: 0.561636
Train - Epoch 0, Batch: 941, Loss: 0.589730
Train - Epoch 0, Batch: 942, Loss: 0.585556
Train - Epoch 0, Batch: 943, Loss: 0.591146
Train - Epoch 0, Batch: 944, Loss: 0.564876
Train - Epoch 0, Batch: 945, Loss: 0.584955
Train - Epoch 0, Batch: 946, Loss: 0.580018
Train - Epoch 0, Batch: 947, Loss: 0.558403
Train - Epoch 0, Batch: 948, Loss: 0.573767
Train - Epoch 0, Batch: 949, Loss: 0.578747
Train - Epoch 0, Batch: 950, Loss: 0.581715
Train - Epoch 0, Batch: 951, Loss: 0.601704
Train - Epoch 0, Batch: 952, Loss: 0.574249
Train - Epoch 0, Batch: 953, Loss: 0.577300
Train - Epoch 0, Batch: 954, Loss: 0.580569
Train - Epoch 0, Batch: 955, Loss: 0.580656
Train - Epoch 0, Batch: 956, Loss: 0.597026
Train - Epoch 0, Batch: 957, Loss: 0.563171
Train - Epoch 0, Batch: 958, Loss: 0.567251
Train - Epoch 0, Batch: 959, Loss: 0.605816
Train - Epoch 0, Batch: 960, Loss: 0.577932
Train - Epoch 0, Batch: 961, Loss: 0.593169
Train - Epoch 0, Batch: 962, Loss: 0.600618
Train - Epoch 0, Batch: 963, Loss: 0.578124
Train - Epoch 0, Batch: 964, Loss: 0.598039
Train - Epoch 0, Batch: 965, Loss: 0.574876
Train - Epoch 0, Batch: 966, Loss: 0.599643
Train - Epoch 0, Batch: 967, Loss: 0.586233
Train - Epoch 0, Batch: 968, Loss: 0.585511
Train - Epoch 0, Batch: 969, Loss: 0.584014
Train - Epoch 0, Batch: 970, Loss: 0.571087
Train - Epoch 0, Batch: 971, Loss: 0.560568
Train - Epoch 0, Batch: 972, Loss: 0.579115
Train - Epoch 0, Batch: 973, Loss: 0.576595
Train - Epoch 0, Batch: 974, Loss: 0.601379
Train - Epoch 0, Batch: 975, Loss: 0.575559
Train - Epoch 0, Batch: 976, Loss: 0.592200
Train - Epoch 0, Batch: 977, Loss: 0.580742
Train - Epoch 0, Batch: 978, Loss: 0.575869
Train - Epoch 0, Batch: 979, Loss: 0.565266
Train - Epoch 0, Batch: 980, Loss: 0.589966
Train - Epoch 0, Batch: 981, Loss: 0.563269
Train - Epoch 0, Batch: 982, Loss: 0.587744
Train - Epoch 0, Batch: 983, Loss: 0.558964
Train - Epoch 0, Batch: 984, Loss: 0.605689
Train - Epoch 0, Batch: 985, Loss: 0.570343
Train - Epoch 0, Batch: 986, Loss: 0.583783
Train - Epoch 0, Batch: 987, Loss: 0.588500
Train - Epoch 0, Batch: 988, Loss: 0.586008
Train - Epoch 0, Batch: 989, Loss: 0.571429
Train - Epoch 0, Batch: 990, Loss: 0.575739
Train - Epoch 0, Batch: 991, Loss: 0.585852
Train - Epoch 0, Batch: 992, Loss: 0.590061
Train - Epoch 0, Batch: 993, Loss: 0.561979
Train - Epoch 0, Batch: 994, Loss: 0.590160
Train - Epoch 0, Batch: 995, Loss: 0.568637
Train - Epoch 0, Batch: 996, Loss: 0.576130
Train - Epoch 0, Batch: 997, Loss: 0.591853
Train - Epoch 0, Batch: 998, Loss: 0.563310
Train - Epoch 0, Batch: 999, Loss: 0.563081
Train - Epoch 0, Batch: 1000, Loss: 0.578778
Train - Epoch 0, Batch: 1001, Loss: 0.609541
Train - Epoch 0, Batch: 1002, Loss: 0.566049
Train - Epoch 0, Batch: 1003, Loss: 0.582504
Train - Epoch 0, Batch: 1004, Loss: 0.567476
Train - Epoch 0, Batch: 1005, Loss: 0.565820
Train - Epoch 0, Batch: 1006, Loss: 0.567479
Train - Epoch 0, Batch: 1007, Loss: 0.591933
Train - Epoch 0, Batch: 1008, Loss: 0.564677
Train - Epoch 0, Batch: 1009, Loss: 0.611545
Train - Epoch 0, Batch: 1010, Loss: 0.578281
Train - Epoch 0, Batch: 1011, Loss: 0.574860
Train - Epoch 0, Batch: 1012, Loss: 0.558907
Train - Epoch 0, Batch: 1013, Loss: 0.583088
Train - Epoch 0, Batch: 1014, Loss: 0.608278
Train - Epoch 0, Batch: 1015, Loss: 0.575726
Train - Epoch 0, Batch: 1016, Loss: 0.576024
Train - Epoch 0, Batch: 1017, Loss: 0.587644
Train - Epoch 0, Batch: 1018, Loss: 0.560370
Train - Epoch 0, Batch: 1019, Loss: 0.580326
Train - Epoch 0, Batch: 1020, Loss: 0.550629
Train - Epoch 0, Batch: 1021, Loss: 0.565174
Train - Epoch 100, Batch: 0, Loss: 0.528942
Train - Epoch 100, Batch: 1, Loss: 0.554043
Train - Epoch 100, Batch: 2, Loss: 0.541945
Train - Epoch 100, Batch: 3, Loss: 0.554855
Train - Epoch 100, Batch: 4, Loss: 0.539735
Train - Epoch 100, Batch: 5, Loss: 0.529322
Train - Epoch 100, Batch: 6, Loss: 0.510744
Train - Epoch 100, Batch: 7, Loss: 0.510275
Train - Epoch 100, Batch: 8, Loss: 0.520736
Train - Epoch 100, Batch: 9, Loss: 0.528515
Train - Epoch 100, Batch: 10, Loss: 0.529414
Train - Epoch 100, Batch: 11, Loss: 0.519053
Train - Epoch 100, Batch: 12, Loss: 0.528339
Train - Epoch 100, Batch: 13, Loss: 0.535772
Train - Epoch 100, Batch: 14, Loss: 0.544956
Train - Epoch 100, Batch: 15, Loss: 0.534895
Train - Epoch 100, Batch: 16, Loss: 0.507325
Train - Epoch 100, Batch: 17, Loss: 0.515850
Train - Epoch 100, Batch: 18, Loss: 0.535869
Train - Epoch 100, Batch: 19, Loss: 0.526180
Train - Epoch 100, Batch: 20, Loss: 0.524217
Train - Epoch 100, Batch: 21, Loss: 0.533109
Train - Epoch 100, Batch: 22, Loss: 0.515477
Train - Epoch 100, Batch: 23, Loss: 0.536507
Train - Epoch 100, Batch: 24, Loss: 0.540559
Train - Epoch 100, Batch: 25, Loss: 0.563377
Train - Epoch 100, Batch: 26, Loss: 0.520406
Train - Epoch 100, Batch: 27, Loss: 0.539644
Train - Epoch 100, Batch: 28, Loss: 0.546295
Train - Epoch 100, Batch: 29, Loss: 0.535511
Train - Epoch 100, Batch: 30, Loss: 0.538933
Train - Epoch 100, Batch: 31, Loss: 0.565581
Train - Epoch 100, Batch: 32, Loss: 0.539510
Train - Epoch 100, Batch: 33, Loss: 0.531143
Train - Epoch 100, Batch: 34, Loss: 0.554221
Train - Epoch 100, Batch: 35, Loss: 0.529634
Train - Epoch 100, Batch: 36, Loss: 0.524302
Train - Epoch 100, Batch: 37, Loss: 0.532296
Train - Epoch 100, Batch: 38, Loss: 0.495508
Train - Epoch 100, Batch: 39, Loss: 0.524823
Train - Epoch 100, Batch: 40, Loss: 0.553864
Train - Epoch 100, Batch: 41, Loss: 0.555075
Train - Epoch 100, Batch: 42, Loss: 0.532924
Train - Epoch 100, Batch: 43, Loss: 0.526821
Train - Epoch 100, Batch: 44, Loss: 0.549941
Train - Epoch 100, Batch: 45, Loss: 0.541699
Train - Epoch 100, Batch: 46, Loss: 0.553015
Train - Epoch 100, Batch: 47, Loss: 0.523402
Train - Epoch 100, Batch: 48, Loss: 0.571407
Train - Epoch 100, Batch: 49, Loss: 0.533353
Train - Epoch 100, Batch: 50, Loss: 0.523869
Train - Epoch 100, Batch: 51, Loss: 0.503744
Train - Epoch 100, Batch: 52, Loss: 0.552939
Train - Epoch 100, Batch: 53, Loss: 0.546874
Train - Epoch 100, Batch: 54, Loss: 0.511090
Train - Epoch 100, Batch: 55, Loss: 0.517604
Train - Epoch 100, Batch: 56, Loss: 0.511274
Train - Epoch 100, Batch: 57, Loss: 0.499055
Train - Epoch 100, Batch: 58, Loss: 0.541802
Train - Epoch 100, Batch: 59, Loss: 0.518735
Train - Epoch 100, Batch: 60, Loss: 0.537364
Train - Epoch 100, Batch: 61, Loss: 0.552473
Train - Epoch 100, Batch: 62, Loss: 0.509727
Train - Epoch 100, Batch: 63, Loss: 0.526514
Train - Epoch 100, Batch: 64, Loss: 0.531584
Train - Epoch 100, Batch: 65, Loss: 0.519610
Train - Epoch 100, Batch: 66, Loss: 0.512180
Train - Epoch 100, Batch: 67, Loss: 0.520144
Train - Epoch 100, Batch: 68, Loss: 0.571863
Train - Epoch 100, Batch: 69, Loss: 0.518121
Train - Epoch 100, Batch: 70, Loss: 0.548329
Train - Epoch 100, Batch: 71, Loss: 0.530205
Train - Epoch 100, Batch: 72, Loss: 0.530418
Train - Epoch 100, Batch: 73, Loss: 0.524380
Train - Epoch 100, Batch: 74, Loss: 0.526201
Train - Epoch 100, Batch: 75, Loss: 0.541336
Train - Epoch 100, Batch: 76, Loss: 0.543158
Train - Epoch 100, Batch: 77, Loss: 0.532712
Train - Epoch 100, Batch: 78, Loss: 0.515202
Train - Epoch 100, Batch: 79, Loss: 0.501684
Train - Epoch 100, Batch: 80, Loss: 0.533197
Train - Epoch 100, Batch: 81, Loss: 0.548383
Train - Epoch 100, Batch: 82, Loss: 0.520254
Train - Epoch 100, Batch: 83, Loss: 0.540696
Train - Epoch 100, Batch: 84, Loss: 0.519802
Train - Epoch 100, Batch: 85, Loss: 0.531174
Train - Epoch 100, Batch: 86, Loss: 0.529631
Train - Epoch 100, Batch: 87, Loss: 0.532464
Train - Epoch 100, Batch: 88, Loss: 0.549618
Train - Epoch 100, Batch: 89, Loss: 0.543355
Train - Epoch 100, Batch: 90, Loss: 0.540089
Train - Epoch 100, Batch: 91, Loss: 0.537311
Train - Epoch 100, Batch: 92, Loss: 0.542914
Train - Epoch 100, Batch: 93, Loss: 0.559418
Train - Epoch 100, Batch: 94, Loss: 0.543657
Train - Epoch 100, Batch: 95, Loss: 0.540863
Train - Epoch 100, Batch: 96, Loss: 0.534711
Train - Epoch 100, Batch: 97, Loss: 0.535069
Train - Epoch 100, Batch: 98, Loss: 0.538347
Train - Epoch 100, Batch: 99, Loss: 0.516676
Train - Epoch 100, Batch: 100, Loss: 0.546272
Train - Epoch 100, Batch: 101, Loss: 0.534642
Train - Epoch 100, Batch: 102, Loss: 0.547970
Train - Epoch 100, Batch: 103, Loss: 0.541829
Train - Epoch 100, Batch: 104, Loss: 0.556343
Train - Epoch 100, Batch: 105, Loss: 0.574395
Train - Epoch 100, Batch: 106, Loss: 0.509664
Train - Epoch 100, Batch: 107, Loss: 0.513839
Train - Epoch 100, Batch: 108, Loss: 0.545123
Train - Epoch 100, Batch: 109, Loss: 0.531198
Train - Epoch 100, Batch: 110, Loss: 0.571246
Train - Epoch 100, Batch: 111, Loss: 0.526410
Train - Epoch 100, Batch: 112, Loss: 0.560403
Train - Epoch 100, Batch: 113, Loss: 0.491920
Train - Epoch 100, Batch: 114, Loss: 0.527042
Train - Epoch 100, Batch: 115, Loss: 0.531243
Train - Epoch 100, Batch: 116, Loss: 0.522440
Train - Epoch 100, Batch: 117, Loss: 0.532293
Train - Epoch 100, Batch: 118, Loss: 0.518658
Train - Epoch 100, Batch: 119, Loss: 0.529146
Train - Epoch 100, Batch: 120, Loss: 0.536004
Train - Epoch 100, Batch: 121, Loss: 0.566683
Train - Epoch 100, Batch: 122, Loss: 0.536048
Train - Epoch 100, Batch: 123, Loss: 0.515472
Train - Epoch 100, Batch: 124, Loss: 0.516406
Train - Epoch 100, Batch: 125, Loss: 0.547918
Train - Epoch 100, Batch: 126, Loss: 0.527729
Train - Epoch 100, Batch: 127, Loss: 0.531637
Train - Epoch 100, Batch: 128, Loss: 0.527919
Train - Epoch 100, Batch: 129, Loss: 0.581139
Train - Epoch 100, Batch: 130, Loss: 0.543776
Train - Epoch 100, Batch: 131, Loss: 0.543618
Train - Epoch 100, Batch: 132, Loss: 0.537969
Train - Epoch 100, Batch: 133, Loss: 0.540700
Train - Epoch 100, Batch: 134, Loss: 0.518448
Train - Epoch 100, Batch: 135, Loss: 0.581475
Train - Epoch 100, Batch: 136, Loss: 0.517446
Train - Epoch 100, Batch: 137, Loss: 0.552572
Train - Epoch 100, Batch: 138, Loss: 0.539640
Train - Epoch 100, Batch: 139, Loss: 0.532822
Train - Epoch 100, Batch: 140, Loss: 0.548426
Train - Epoch 100, Batch: 141, Loss: 0.554814
Train - Epoch 100, Batch: 142, Loss: 0.504609
Train - Epoch 100, Batch: 143, Loss: 0.529460
Train - Epoch 100, Batch: 144, Loss: 0.539369
Train - Epoch 100, Batch: 145, Loss: 0.543464
Train - Epoch 100, Batch: 146, Loss: 0.548666
Train - Epoch 100, Batch: 147, Loss: 0.484023
Train - Epoch 100, Batch: 148, Loss: 0.535512
Train - Epoch 100, Batch: 149, Loss: 0.526381
Train - Epoch 100, Batch: 150, Loss: 0.549324
Train - Epoch 100, Batch: 151, Loss: 0.521515
Train - Epoch 100, Batch: 152, Loss: 0.519911
Train - Epoch 100, Batch: 153, Loss: 0.562812
Train - Epoch 100, Batch: 154, Loss: 0.540904
Train - Epoch 100, Batch: 155, Loss: 0.517250
Train - Epoch 100, Batch: 156, Loss: 0.504977
Train - Epoch 100, Batch: 157, Loss: 0.515585
Train - Epoch 100, Batch: 158, Loss: 0.541175
Train - Epoch 100, Batch: 159, Loss: 0.555922
Train - Epoch 100, Batch: 160, Loss: 0.544635
Train - Epoch 100, Batch: 161, Loss: 0.576196
Train - Epoch 100, Batch: 162, Loss: 0.552642
Train - Epoch 100, Batch: 163, Loss: 0.514849
Train - Epoch 100, Batch: 164, Loss: 0.557848
Train - Epoch 100, Batch: 165, Loss: 0.524359
Train - Epoch 100, Batch: 166, Loss: 0.546722
Train - Epoch 100, Batch: 167, Loss: 0.526478
Train - Epoch 100, Batch: 168, Loss: 0.527642
Train - Epoch 100, Batch: 169, Loss: 0.530599
Train - Epoch 100, Batch: 170, Loss: 0.546314
Train - Epoch 100, Batch: 171, Loss: 0.570589
Train - Epoch 100, Batch: 172, Loss: 0.503208
Train - Epoch 100, Batch: 173, Loss: 0.561728
Train - Epoch 100, Batch: 174, Loss: 0.541064
Train - Epoch 100, Batch: 175, Loss: 0.532630
Train - Epoch 100, Batch: 176, Loss: 0.549421
Train - Epoch 100, Batch: 177, Loss: 0.528807
Train - Epoch 100, Batch: 178, Loss: 0.569455
Train - Epoch 100, Batch: 179, Loss: 0.554804
Train - Epoch 100, Batch: 180, Loss: 0.524411
Train - Epoch 100, Batch: 181, Loss: 0.553727
Train - Epoch 100, Batch: 182, Loss: 0.516863
Train - Epoch 100, Batch: 183, Loss: 0.533110
Train - Epoch 100, Batch: 184, Loss: 0.504276
Train - Epoch 100, Batch: 185, Loss: 0.544469
Train - Epoch 100, Batch: 186, Loss: 0.537906
Train - Epoch 100, Batch: 187, Loss: 0.527596
Train - Epoch 100, Batch: 188, Loss: 0.507999
Train - Epoch 100, Batch: 189, Loss: 0.539126
Train - Epoch 100, Batch: 190, Loss: 0.555367
Train - Epoch 100, Batch: 191, Loss: 0.553118
Train - Epoch 100, Batch: 192, Loss: 0.549370
Train - Epoch 100, Batch: 193, Loss: 0.526742
Train - Epoch 100, Batch: 194, Loss: 0.561043
Train - Epoch 100, Batch: 195, Loss: 0.518031
Train - Epoch 100, Batch: 196, Loss: 0.546246
Train - Epoch 100, Batch: 197, Loss: 0.553653
Train - Epoch 100, Batch: 198, Loss: 0.528900
Train - Epoch 100, Batch: 199, Loss: 0.543507
Train - Epoch 100, Batch: 200, Loss: 0.500596
Train - Epoch 100, Batch: 201, Loss: 0.541651
Train - Epoch 100, Batch: 202, Loss: 0.511338
Train - Epoch 100, Batch: 203, Loss: 0.546180
Train - Epoch 100, Batch: 204, Loss: 0.537566
Train - Epoch 100, Batch: 205, Loss: 0.542680
Train - Epoch 100, Batch: 206, Loss: 0.524567
Train - Epoch 100, Batch: 207, Loss: 0.534979
Train - Epoch 100, Batch: 208, Loss: 0.539417
Train - Epoch 100, Batch: 209, Loss: 0.557650
Train - Epoch 100, Batch: 210, Loss: 0.528438
Train - Epoch 100, Batch: 211, Loss: 0.537738
Train - Epoch 100, Batch: 212, Loss: 0.523870
Train - Epoch 100, Batch: 213, Loss: 0.535112
Train - Epoch 100, Batch: 214, Loss: 0.541584
Train - Epoch 100, Batch: 215, Loss: 0.508818
Train - Epoch 100, Batch: 216, Loss: 0.536835
Train - Epoch 100, Batch: 217, Loss: 0.528881
Train - Epoch 100, Batch: 218, Loss: 0.564092
Train - Epoch 100, Batch: 219, Loss: 0.508956
Train - Epoch 100, Batch: 220, Loss: 0.528962
Train - Epoch 100, Batch: 221, Loss: 0.535775
Train - Epoch 100, Batch: 222, Loss: 0.516979
Train - Epoch 100, Batch: 223, Loss: 0.551047
Train - Epoch 100, Batch: 224, Loss: 0.514260
Train - Epoch 100, Batch: 225, Loss: 0.514202
Train - Epoch 100, Batch: 226, Loss: 0.538224
Train - Epoch 100, Batch: 227, Loss: 0.521290
Train - Epoch 100, Batch: 228, Loss: 0.549521
Train - Epoch 100, Batch: 229, Loss: 0.575882
Train - Epoch 100, Batch: 230, Loss: 0.504646
Train - Epoch 100, Batch: 231, Loss: 0.527891
Train - Epoch 100, Batch: 232, Loss: 0.517303
Train - Epoch 100, Batch: 233, Loss: 0.528247
Train - Epoch 100, Batch: 234, Loss: 0.536085
Train - Epoch 100, Batch: 235, Loss: 0.539768
Train - Epoch 100, Batch: 236, Loss: 0.547180
Train - Epoch 100, Batch: 237, Loss: 0.522908
Train - Epoch 100, Batch: 238, Loss: 0.514669
Train - Epoch 100, Batch: 239, Loss: 0.531938
Train - Epoch 100, Batch: 240, Loss: 0.538853
Train - Epoch 100, Batch: 241, Loss: 0.550431
Train - Epoch 100, Batch: 242, Loss: 0.519279
Train - Epoch 100, Batch: 243, Loss: 0.550748
Train - Epoch 100, Batch: 244, Loss: 0.520866
Train - Epoch 100, Batch: 245, Loss: 0.569470
Train - Epoch 100, Batch: 246, Loss: 0.551499
Train - Epoch 100, Batch: 247, Loss: 0.539993
Train - Epoch 100, Batch: 248, Loss: 0.548554
Train - Epoch 100, Batch: 249, Loss: 0.528334
Train - Epoch 100, Batch: 250, Loss: 0.535910
Train - Epoch 100, Batch: 251, Loss: 0.537696
Train - Epoch 100, Batch: 252, Loss: 0.557045
Train - Epoch 100, Batch: 253, Loss: 0.519869
Train - Epoch 100, Batch: 254, Loss: 0.518662
Train - Epoch 100, Batch: 255, Loss: 0.528896
Train - Epoch 100, Batch: 256, Loss: 0.536863
Train - Epoch 100, Batch: 257, Loss: 0.522241
Train - Epoch 100, Batch: 258, Loss: 0.554471
Train - Epoch 100, Batch: 259, Loss: 0.544233
Train - Epoch 100, Batch: 260, Loss: 0.541933
Train - Epoch 100, Batch: 261, Loss: 0.517391
Train - Epoch 100, Batch: 262, Loss: 0.525611
Train - Epoch 100, Batch: 263, Loss: 0.530256
Train - Epoch 100, Batch: 264, Loss: 0.511107
Train - Epoch 100, Batch: 265, Loss: 0.512380
Train - Epoch 100, Batch: 266, Loss: 0.531630
Train - Epoch 100, Batch: 267, Loss: 0.520501
Train - Epoch 100, Batch: 268, Loss: 0.544726
Train - Epoch 100, Batch: 269, Loss: 0.518320
Train - Epoch 100, Batch: 270, Loss: 0.535948
Train - Epoch 100, Batch: 271, Loss: 0.552988
Train - Epoch 100, Batch: 272, Loss: 0.522350
Train - Epoch 100, Batch: 273, Loss: 0.512557
Train - Epoch 100, Batch: 274, Loss: 0.510503
Train - Epoch 100, Batch: 275, Loss: 0.506107
Train - Epoch 100, Batch: 276, Loss: 0.559422
Train - Epoch 100, Batch: 277, Loss: 0.526391
Train - Epoch 100, Batch: 278, Loss: 0.534459
Train - Epoch 100, Batch: 279, Loss: 0.517936
Train - Epoch 100, Batch: 280, Loss: 0.542293
Train - Epoch 100, Batch: 281, Loss: 0.544958
Train - Epoch 100, Batch: 282, Loss: 0.541038
Train - Epoch 100, Batch: 283, Loss: 0.549181
Train - Epoch 100, Batch: 284, Loss: 0.524052
Train - Epoch 100, Batch: 285, Loss: 0.537181
Train - Epoch 100, Batch: 286, Loss: 0.537001
Train - Epoch 100, Batch: 287, Loss: 0.565967
Train - Epoch 100, Batch: 288, Loss: 0.553911
Train - Epoch 100, Batch: 289, Loss: 0.504478
Train - Epoch 100, Batch: 290, Loss: 0.549138
Train - Epoch 100, Batch: 291, Loss: 0.544520
Train - Epoch 100, Batch: 292, Loss: 0.516571
Train - Epoch 100, Batch: 293, Loss: 0.557239
Train - Epoch 100, Batch: 294, Loss: 0.560564
Train - Epoch 100, Batch: 295, Loss: 0.523680
Train - Epoch 100, Batch: 296, Loss: 0.551957
Train - Epoch 100, Batch: 297, Loss: 0.557418
Train - Epoch 100, Batch: 298, Loss: 0.535283
Train - Epoch 100, Batch: 299, Loss: 0.530777
Train - Epoch 100, Batch: 300, Loss: 0.555494
Train - Epoch 100, Batch: 301, Loss: 0.511163
Train - Epoch 100, Batch: 302, Loss: 0.519479
Train - Epoch 100, Batch: 303, Loss: 0.550118
Train - Epoch 100, Batch: 304, Loss: 0.532793
Train - Epoch 100, Batch: 305, Loss: 0.534829
Train - Epoch 100, Batch: 306, Loss: 0.520014
Train - Epoch 100, Batch: 307, Loss: 0.543783
Train - Epoch 100, Batch: 308, Loss: 0.558738
Train - Epoch 100, Batch: 309, Loss: 0.550229
Train - Epoch 100, Batch: 310, Loss: 0.507891
Train - Epoch 100, Batch: 311, Loss: 0.517758
Train - Epoch 100, Batch: 312, Loss: 0.551310
Train - Epoch 100, Batch: 313, Loss: 0.537001
Train - Epoch 100, Batch: 314, Loss: 0.532245
Train - Epoch 100, Batch: 315, Loss: 0.511523
Train - Epoch 100, Batch: 316, Loss: 0.519808
Train - Epoch 100, Batch: 317, Loss: 0.516044
Train - Epoch 100, Batch: 318, Loss: 0.526782
Train - Epoch 100, Batch: 319, Loss: 0.545552
Train - Epoch 100, Batch: 320, Loss: 0.527148
Train - Epoch 100, Batch: 321, Loss: 0.524948
Train - Epoch 100, Batch: 322, Loss: 0.536934
Train - Epoch 100, Batch: 323, Loss: 0.561962
Train - Epoch 100, Batch: 324, Loss: 0.539431
Train - Epoch 100, Batch: 325, Loss: 0.539045
Train - Epoch 100, Batch: 326, Loss: 0.523860
Train - Epoch 100, Batch: 327, Loss: 0.506015
Train - Epoch 100, Batch: 328, Loss: 0.522563
Train - Epoch 100, Batch: 329, Loss: 0.525075
Train - Epoch 100, Batch: 330, Loss: 0.551356
Train - Epoch 100, Batch: 331, Loss: 0.548631
Train - Epoch 100, Batch: 332, Loss: 0.528264
Train - Epoch 100, Batch: 333, Loss: 0.497093
Train - Epoch 100, Batch: 334, Loss: 0.561132
Train - Epoch 100, Batch: 335, Loss: 0.555482
Train - Epoch 100, Batch: 336, Loss: 0.527581
Train - Epoch 100, Batch: 337, Loss: 0.544874
Train - Epoch 100, Batch: 338, Loss: 0.525651
Train - Epoch 100, Batch: 339, Loss: 0.511171
Train - Epoch 100, Batch: 340, Loss: 0.550061
Train - Epoch 100, Batch: 341, Loss: 0.541198
Train - Epoch 100, Batch: 342, Loss: 0.520917
Train - Epoch 100, Batch: 343, Loss: 0.550723
Train - Epoch 100, Batch: 344, Loss: 0.490161
Train - Epoch 100, Batch: 345, Loss: 0.533949
Train - Epoch 100, Batch: 346, Loss: 0.533466
Train - Epoch 100, Batch: 347, Loss: 0.518251
Train - Epoch 100, Batch: 348, Loss: 0.530737
Train - Epoch 100, Batch: 349, Loss: 0.541906
Train - Epoch 100, Batch: 350, Loss: 0.560182
Train - Epoch 100, Batch: 351, Loss: 0.544936
Train - Epoch 100, Batch: 352, Loss: 0.554262
Train - Epoch 100, Batch: 353, Loss: 0.526239
Train - Epoch 100, Batch: 354, Loss: 0.537209
Train - Epoch 100, Batch: 355, Loss: 0.529568
Train - Epoch 100, Batch: 356, Loss: 0.531332
Train - Epoch 100, Batch: 357, Loss: 0.525467
Train - Epoch 100, Batch: 358, Loss: 0.543510
Train - Epoch 100, Batch: 359, Loss: 0.527957
Train - Epoch 100, Batch: 360, Loss: 0.521341
Train - Epoch 100, Batch: 361, Loss: 0.539311
Train - Epoch 100, Batch: 362, Loss: 0.529302
Train - Epoch 100, Batch: 363, Loss: 0.521138
Train - Epoch 100, Batch: 364, Loss: 0.532954
Train - Epoch 100, Batch: 365, Loss: 0.532304
Train - Epoch 100, Batch: 366, Loss: 0.537704
Train - Epoch 100, Batch: 367, Loss: 0.533431
Train - Epoch 100, Batch: 368, Loss: 0.548575
Train - Epoch 100, Batch: 369, Loss: 0.578166
Train - Epoch 100, Batch: 370, Loss: 0.518228
Train - Epoch 100, Batch: 371, Loss: 0.525246
Train - Epoch 100, Batch: 372, Loss: 0.552508
Train - Epoch 100, Batch: 373, Loss: 0.515893
Train - Epoch 100, Batch: 374, Loss: 0.542006
Train - Epoch 100, Batch: 375, Loss: 0.534338
Train - Epoch 100, Batch: 376, Loss: 0.564528
Train - Epoch 100, Batch: 377, Loss: 0.520913
Train - Epoch 100, Batch: 378, Loss: 0.543618
Train - Epoch 100, Batch: 379, Loss: 0.546168
Train - Epoch 100, Batch: 380, Loss: 0.524418
Train - Epoch 100, Batch: 381, Loss: 0.522802
Train - Epoch 100, Batch: 382, Loss: 0.536549
Train - Epoch 100, Batch: 383, Loss: 0.524536
Train - Epoch 100, Batch: 384, Loss: 0.553886
Train - Epoch 100, Batch: 385, Loss: 0.540037
Train - Epoch 100, Batch: 386, Loss: 0.519962
Train - Epoch 100, Batch: 387, Loss: 0.516248
Train - Epoch 100, Batch: 388, Loss: 0.535008
Train - Epoch 100, Batch: 389, Loss: 0.554953
Train - Epoch 100, Batch: 390, Loss: 0.525735
Train - Epoch 100, Batch: 391, Loss: 0.536022
Train - Epoch 100, Batch: 392, Loss: 0.563712
Train - Epoch 100, Batch: 393, Loss: 0.526699
Train - Epoch 100, Batch: 394, Loss: 0.552387
Train - Epoch 100, Batch: 395, Loss: 0.530403
Train - Epoch 100, Batch: 396, Loss: 0.544139
Train - Epoch 100, Batch: 397, Loss: 0.520608
Train - Epoch 100, Batch: 398, Loss: 0.560782
Train - Epoch 100, Batch: 399, Loss: 0.538757
Train - Epoch 100, Batch: 400, Loss: 0.509852
Train - Epoch 100, Batch: 401, Loss: 0.518630
Train - Epoch 100, Batch: 402, Loss: 0.538190
Train - Epoch 100, Batch: 403, Loss: 0.526371
Train - Epoch 100, Batch: 404, Loss: 0.529274
Train - Epoch 100, Batch: 405, Loss: 0.508258
Train - Epoch 100, Batch: 406, Loss: 0.520031
Train - Epoch 100, Batch: 407, Loss: 0.511958
Train - Epoch 100, Batch: 408, Loss: 0.528412
Train - Epoch 100, Batch: 409, Loss: 0.564447
Train - Epoch 100, Batch: 410, Loss: 0.522085
Train - Epoch 100, Batch: 411, Loss: 0.536941
Train - Epoch 100, Batch: 412, Loss: 0.574265
Train - Epoch 100, Batch: 413, Loss: 0.539934
Train - Epoch 100, Batch: 414, Loss: 0.534676
Train - Epoch 100, Batch: 415, Loss: 0.534141
Train - Epoch 100, Batch: 416, Loss: 0.523161
Train - Epoch 100, Batch: 417, Loss: 0.506997
Train - Epoch 100, Batch: 418, Loss: 0.533562
Train - Epoch 100, Batch: 419, Loss: 0.539464
Train - Epoch 100, Batch: 420, Loss: 0.563592
Train - Epoch 100, Batch: 421, Loss: 0.539373
Train - Epoch 100, Batch: 422, Loss: 0.534390
Train - Epoch 100, Batch: 423, Loss: 0.557538
Train - Epoch 100, Batch: 424, Loss: 0.534824
Train - Epoch 100, Batch: 425, Loss: 0.528057
Train - Epoch 100, Batch: 426, Loss: 0.515246
Train - Epoch 100, Batch: 427, Loss: 0.537387
Train - Epoch 100, Batch: 428, Loss: 0.534062
Train - Epoch 100, Batch: 429, Loss: 0.540872
Train - Epoch 100, Batch: 430, Loss: 0.542801
Train - Epoch 100, Batch: 431, Loss: 0.542490
Train - Epoch 100, Batch: 432, Loss: 0.533262
Train - Epoch 100, Batch: 433, Loss: 0.540309
Train - Epoch 100, Batch: 434, Loss: 0.545880
Train - Epoch 100, Batch: 435, Loss: 0.560799
Train - Epoch 100, Batch: 436, Loss: 0.550911
Train - Epoch 100, Batch: 437, Loss: 0.534200
Train - Epoch 100, Batch: 438, Loss: 0.568063
Train - Epoch 100, Batch: 439, Loss: 0.559868
Train - Epoch 100, Batch: 440, Loss: 0.539069
Train - Epoch 100, Batch: 441, Loss: 0.524825
Train - Epoch 100, Batch: 442, Loss: 0.533984
Train - Epoch 100, Batch: 443, Loss: 0.547272
Train - Epoch 100, Batch: 444, Loss: 0.574806
Train - Epoch 100, Batch: 445, Loss: 0.535256
Train - Epoch 100, Batch: 446, Loss: 0.513485
Train - Epoch 100, Batch: 447, Loss: 0.530212
Train - Epoch 100, Batch: 448, Loss: 0.535597
Train - Epoch 100, Batch: 449, Loss: 0.539750
Train - Epoch 100, Batch: 450, Loss: 0.526341
Train - Epoch 100, Batch: 451, Loss: 0.544825
Train - Epoch 100, Batch: 452, Loss: 0.562359
Train - Epoch 100, Batch: 453, Loss: 0.541483
Train - Epoch 100, Batch: 454, Loss: 0.503132
Train - Epoch 100, Batch: 455, Loss: 0.545068
Train - Epoch 100, Batch: 456, Loss: 0.558407
Train - Epoch 100, Batch: 457, Loss: 0.525816
Train - Epoch 100, Batch: 458, Loss: 0.537663
Train - Epoch 100, Batch: 459, Loss: 0.528696
Train - Epoch 100, Batch: 460, Loss: 0.550174
Train - Epoch 100, Batch: 461, Loss: 0.541066
Train - Epoch 100, Batch: 462, Loss: 0.571267
Train - Epoch 100, Batch: 463, Loss: 0.522068
Train - Epoch 100, Batch: 464, Loss: 0.498896
Train - Epoch 100, Batch: 465, Loss: 0.553491
Train - Epoch 100, Batch: 466, Loss: 0.540327
Train - Epoch 100, Batch: 467, Loss: 0.540920
Train - Epoch 100, Batch: 468, Loss: 0.544931
Train - Epoch 100, Batch: 469, Loss: 0.526978
Train - Epoch 100, Batch: 470, Loss: 0.533604
Train - Epoch 100, Batch: 471, Loss: 0.522965
Train - Epoch 100, Batch: 472, Loss: 0.561254
Train - Epoch 100, Batch: 473, Loss: 0.534040
Train - Epoch 100, Batch: 474, Loss: 0.538256
Train - Epoch 100, Batch: 475, Loss: 0.508577
Train - Epoch 100, Batch: 476, Loss: 0.522893
Train - Epoch 100, Batch: 477, Loss: 0.542049
Train - Epoch 100, Batch: 478, Loss: 0.563699
Train - Epoch 100, Batch: 479, Loss: 0.539803
Train - Epoch 100, Batch: 480, Loss: 0.542612
Train - Epoch 100, Batch: 481, Loss: 0.508843
Train - Epoch 100, Batch: 482, Loss: 0.522590
Train - Epoch 100, Batch: 483, Loss: 0.521856
Train - Epoch 100, Batch: 484, Loss: 0.539136
Train - Epoch 100, Batch: 485, Loss: 0.566156
Train - Epoch 100, Batch: 486, Loss: 0.552579
Train - Epoch 100, Batch: 487, Loss: 0.545558
Train - Epoch 100, Batch: 488, Loss: 0.526941
Train - Epoch 100, Batch: 489, Loss: 0.521495
Train - Epoch 100, Batch: 490, Loss: 0.551948
Train - Epoch 100, Batch: 491, Loss: 0.561371
Train - Epoch 100, Batch: 492, Loss: 0.515034
Train - Epoch 100, Batch: 493, Loss: 0.540617
Train - Epoch 100, Batch: 494, Loss: 0.525489
Train - Epoch 100, Batch: 495, Loss: 0.520004
Train - Epoch 100, Batch: 496, Loss: 0.558308
Train - Epoch 100, Batch: 497, Loss: 0.533342
Train - Epoch 100, Batch: 498, Loss: 0.518818
Train - Epoch 100, Batch: 499, Loss: 0.526778
Train - Epoch 100, Batch: 500, Loss: 0.553018
Train - Epoch 100, Batch: 501, Loss: 0.541552
Train - Epoch 100, Batch: 502, Loss: 0.546332
Train - Epoch 100, Batch: 503, Loss: 0.537784
Train - Epoch 100, Batch: 504, Loss: 0.547654
Train - Epoch 100, Batch: 505, Loss: 0.541664
Train - Epoch 100, Batch: 506, Loss: 0.518548
Train - Epoch 100, Batch: 507, Loss: 0.528914
Train - Epoch 100, Batch: 508, Loss: 0.532004
Train - Epoch 100, Batch: 509, Loss: 0.556742
Train - Epoch 100, Batch: 510, Loss: 0.515182
Train - Epoch 100, Batch: 511, Loss: 0.519178
Train - Epoch 100, Batch: 512, Loss: 0.528201
Train - Epoch 100, Batch: 513, Loss: 0.539180
Train - Epoch 100, Batch: 514, Loss: 0.508948
Train - Epoch 100, Batch: 515, Loss: 0.522210
Train - Epoch 100, Batch: 516, Loss: 0.525064
Train - Epoch 100, Batch: 517, Loss: 0.527727
Train - Epoch 100, Batch: 518, Loss: 0.554251
Train - Epoch 100, Batch: 519, Loss: 0.563662
Train - Epoch 100, Batch: 520, Loss: 0.500387
Train - Epoch 100, Batch: 521, Loss: 0.536743
Train - Epoch 100, Batch: 522, Loss: 0.526288
Train - Epoch 100, Batch: 523, Loss: 0.560219
Train - Epoch 100, Batch: 524, Loss: 0.530223
Train - Epoch 100, Batch: 525, Loss: 0.524018
Train - Epoch 100, Batch: 526, Loss: 0.552994
Train - Epoch 100, Batch: 527, Loss: 0.539657
Train - Epoch 100, Batch: 528, Loss: 0.547845
Train - Epoch 100, Batch: 529, Loss: 0.531406
Train - Epoch 100, Batch: 530, Loss: 0.517832
Train - Epoch 100, Batch: 531, Loss: 0.507435
Train - Epoch 100, Batch: 532, Loss: 0.545829
Train - Epoch 100, Batch: 533, Loss: 0.532748
Train - Epoch 100, Batch: 534, Loss: 0.539744
Train - Epoch 100, Batch: 535, Loss: 0.532736
Train - Epoch 100, Batch: 536, Loss: 0.531293
Train - Epoch 100, Batch: 537, Loss: 0.510837
Train - Epoch 100, Batch: 538, Loss: 0.532068
Train - Epoch 100, Batch: 539, Loss: 0.515082
Train - Epoch 100, Batch: 540, Loss: 0.520837
Train - Epoch 100, Batch: 541, Loss: 0.539902
Train - Epoch 100, Batch: 542, Loss: 0.534711
Train - Epoch 100, Batch: 543, Loss: 0.521896
Train - Epoch 100, Batch: 544, Loss: 0.552970
Train - Epoch 100, Batch: 545, Loss: 0.519402
Train - Epoch 100, Batch: 546, Loss: 0.556486
Train - Epoch 100, Batch: 547, Loss: 0.505319
Train - Epoch 100, Batch: 548, Loss: 0.546418
Train - Epoch 100, Batch: 549, Loss: 0.524887
Train - Epoch 100, Batch: 550, Loss: 0.539859
Train - Epoch 100, Batch: 551, Loss: 0.538924
Train - Epoch 100, Batch: 552, Loss: 0.537927
Train - Epoch 100, Batch: 553, Loss: 0.546844
Train - Epoch 100, Batch: 554, Loss: 0.534938
Train - Epoch 100, Batch: 555, Loss: 0.527866
Train - Epoch 100, Batch: 556, Loss: 0.536454
Train - Epoch 100, Batch: 557, Loss: 0.552329
Train - Epoch 100, Batch: 558, Loss: 0.534702
Train - Epoch 100, Batch: 559, Loss: 0.522936
Train - Epoch 100, Batch: 560, Loss: 0.532435
Train - Epoch 100, Batch: 561, Loss: 0.537063
Train - Epoch 100, Batch: 562, Loss: 0.533094
Train - Epoch 100, Batch: 563, Loss: 0.545253
Train - Epoch 100, Batch: 564, Loss: 0.533964
Train - Epoch 100, Batch: 565, Loss: 0.545319
Train - Epoch 100, Batch: 566, Loss: 0.544189
Train - Epoch 100, Batch: 567, Loss: 0.545707
Train - Epoch 100, Batch: 568, Loss: 0.534026
Train - Epoch 100, Batch: 569, Loss: 0.510849
Train - Epoch 100, Batch: 570, Loss: 0.509236
Train - Epoch 100, Batch: 571, Loss: 0.539771
Train - Epoch 100, Batch: 572, Loss: 0.534790
Train - Epoch 100, Batch: 573, Loss: 0.537801
Train - Epoch 100, Batch: 574, Loss: 0.547659
Train - Epoch 100, Batch: 575, Loss: 0.541076
Train - Epoch 100, Batch: 576, Loss: 0.515585
Train - Epoch 100, Batch: 577, Loss: 0.547117
Train - Epoch 100, Batch: 578, Loss: 0.565559
Train - Epoch 100, Batch: 579, Loss: 0.549726
Train - Epoch 100, Batch: 580, Loss: 0.533977
Train - Epoch 100, Batch: 581, Loss: 0.569550
Train - Epoch 100, Batch: 582, Loss: 0.554643
Train - Epoch 100, Batch: 583, Loss: 0.528063
Train - Epoch 100, Batch: 584, Loss: 0.550703
Train - Epoch 100, Batch: 585, Loss: 0.561059
Train - Epoch 100, Batch: 586, Loss: 0.571971
Train - Epoch 100, Batch: 587, Loss: 0.523904
Train - Epoch 100, Batch: 588, Loss: 0.523705
Train - Epoch 100, Batch: 589, Loss: 0.504669
Train - Epoch 100, Batch: 590, Loss: 0.538390
Train - Epoch 100, Batch: 591, Loss: 0.541264
Train - Epoch 100, Batch: 592, Loss: 0.553422
Train - Epoch 100, Batch: 593, Loss: 0.539837
Train - Epoch 100, Batch: 594, Loss: 0.562217
Train - Epoch 100, Batch: 595, Loss: 0.525239
Train - Epoch 100, Batch: 596, Loss: 0.538904
Train - Epoch 100, Batch: 597, Loss: 0.537726
Train - Epoch 100, Batch: 598, Loss: 0.539875
Train - Epoch 100, Batch: 599, Loss: 0.528745
Train - Epoch 100, Batch: 600, Loss: 0.526146
Train - Epoch 100, Batch: 601, Loss: 0.526656
Train - Epoch 100, Batch: 602, Loss: 0.538098
Train - Epoch 100, Batch: 603, Loss: 0.539957
Train - Epoch 100, Batch: 604, Loss: 0.552963
Train - Epoch 100, Batch: 605, Loss: 0.505912
Train - Epoch 100, Batch: 606, Loss: 0.529288
Train - Epoch 100, Batch: 607, Loss: 0.544233
Train - Epoch 100, Batch: 608, Loss: 0.542065
Train - Epoch 100, Batch: 609, Loss: 0.569373
Train - Epoch 100, Batch: 610, Loss: 0.527904
Train - Epoch 100, Batch: 611, Loss: 0.529576
Train - Epoch 100, Batch: 612, Loss: 0.527143
Train - Epoch 100, Batch: 613, Loss: 0.516352
Train - Epoch 100, Batch: 614, Loss: 0.485211
Train - Epoch 100, Batch: 615, Loss: 0.538176
Train - Epoch 100, Batch: 616, Loss: 0.503610
Train - Epoch 100, Batch: 617, Loss: 0.495933
Train - Epoch 100, Batch: 618, Loss: 0.537824
Train - Epoch 100, Batch: 619, Loss: 0.538733
Train - Epoch 100, Batch: 620, Loss: 0.530287
Train - Epoch 100, Batch: 621, Loss: 0.529972
Train - Epoch 100, Batch: 622, Loss: 0.511392
Train - Epoch 100, Batch: 623, Loss: 0.532879
Train - Epoch 100, Batch: 624, Loss: 0.523590
Train - Epoch 100, Batch: 625, Loss: 0.518806
Train - Epoch 100, Batch: 626, Loss: 0.561942
Train - Epoch 100, Batch: 627, Loss: 0.529980
Train - Epoch 100, Batch: 628, Loss: 0.513789
Train - Epoch 100, Batch: 629, Loss: 0.570324
Train - Epoch 100, Batch: 630, Loss: 0.535638
Train - Epoch 100, Batch: 631, Loss: 0.528643
Train - Epoch 100, Batch: 632, Loss: 0.537979
Train - Epoch 100, Batch: 633, Loss: 0.530761
Train - Epoch 100, Batch: 634, Loss: 0.545240
Train - Epoch 100, Batch: 635, Loss: 0.550080
Train - Epoch 100, Batch: 636, Loss: 0.578100
Train - Epoch 100, Batch: 637, Loss: 0.555066
Train - Epoch 100, Batch: 638, Loss: 0.496518
Train - Epoch 100, Batch: 639, Loss: 0.518589
Train - Epoch 100, Batch: 640, Loss: 0.526805
Train - Epoch 100, Batch: 641, Loss: 0.520470
Train - Epoch 100, Batch: 642, Loss: 0.551811
Train - Epoch 100, Batch: 643, Loss: 0.508815
Train - Epoch 100, Batch: 644, Loss: 0.532100
Train - Epoch 100, Batch: 645, Loss: 0.536105
Train - Epoch 100, Batch: 646, Loss: 0.523295
Train - Epoch 100, Batch: 647, Loss: 0.513392
Train - Epoch 100, Batch: 648, Loss: 0.503555
Train - Epoch 100, Batch: 649, Loss: 0.537815
Train - Epoch 100, Batch: 650, Loss: 0.524217
Train - Epoch 100, Batch: 651, Loss: 0.527908
Train - Epoch 100, Batch: 652, Loss: 0.519557
Train - Epoch 100, Batch: 653, Loss: 0.529923
Train - Epoch 100, Batch: 654, Loss: 0.519195
Train - Epoch 100, Batch: 655, Loss: 0.509858
Train - Epoch 100, Batch: 656, Loss: 0.538763
Train - Epoch 100, Batch: 657, Loss: 0.531813
Train - Epoch 100, Batch: 658, Loss: 0.529404
Train - Epoch 100, Batch: 659, Loss: 0.553928
Train - Epoch 100, Batch: 660, Loss: 0.543842
Train - Epoch 100, Batch: 661, Loss: 0.533547
Train - Epoch 100, Batch: 662, Loss: 0.537849
Train - Epoch 100, Batch: 663, Loss: 0.548827
Train - Epoch 100, Batch: 664, Loss: 0.554156
Train - Epoch 100, Batch: 665, Loss: 0.531373
Train - Epoch 100, Batch: 666, Loss: 0.526476
Train - Epoch 100, Batch: 667, Loss: 0.514080
Train - Epoch 100, Batch: 668, Loss: 0.544751
Train - Epoch 100, Batch: 669, Loss: 0.572797
Train - Epoch 100, Batch: 670, Loss: 0.550409
Train - Epoch 100, Batch: 671, Loss: 0.514725
Train - Epoch 100, Batch: 672, Loss: 0.534048
Train - Epoch 100, Batch: 673, Loss: 0.507863
Train - Epoch 100, Batch: 674, Loss: 0.539045
Train - Epoch 100, Batch: 675, Loss: 0.522145
Train - Epoch 100, Batch: 676, Loss: 0.549635
Train - Epoch 100, Batch: 677, Loss: 0.559464
Train - Epoch 100, Batch: 678, Loss: 0.522654
Train - Epoch 100, Batch: 679, Loss: 0.538363
Train - Epoch 100, Batch: 680, Loss: 0.552587
Train - Epoch 100, Batch: 681, Loss: 0.536259
Train - Epoch 100, Batch: 682, Loss: 0.503171
Train - Epoch 100, Batch: 683, Loss: 0.518321
Train - Epoch 100, Batch: 684, Loss: 0.518960
Train - Epoch 100, Batch: 685, Loss: 0.531445
Train - Epoch 100, Batch: 686, Loss: 0.528648
Train - Epoch 100, Batch: 687, Loss: 0.559619
Train - Epoch 100, Batch: 688, Loss: 0.551567
Train - Epoch 100, Batch: 689, Loss: 0.566947
Train - Epoch 100, Batch: 690, Loss: 0.535048
Train - Epoch 100, Batch: 691, Loss: 0.571095
Train - Epoch 100, Batch: 692, Loss: 0.493300
Train - Epoch 100, Batch: 693, Loss: 0.525947
Train - Epoch 100, Batch: 694, Loss: 0.544351
Train - Epoch 100, Batch: 695, Loss: 0.549672
Train - Epoch 100, Batch: 696, Loss: 0.543060
Train - Epoch 100, Batch: 697, Loss: 0.517003
Train - Epoch 100, Batch: 698, Loss: 0.533277
Train - Epoch 100, Batch: 699, Loss: 0.531400
Train - Epoch 100, Batch: 700, Loss: 0.538817
Train - Epoch 100, Batch: 701, Loss: 0.539948
Train - Epoch 100, Batch: 702, Loss: 0.543404
Train - Epoch 100, Batch: 703, Loss: 0.510842
Train - Epoch 100, Batch: 704, Loss: 0.520739
Train - Epoch 100, Batch: 705, Loss: 0.539711
Train - Epoch 100, Batch: 706, Loss: 0.530048
Train - Epoch 100, Batch: 707, Loss: 0.517638
Train - Epoch 100, Batch: 708, Loss: 0.549171
Train - Epoch 100, Batch: 709, Loss: 0.549136
Train - Epoch 100, Batch: 710, Loss: 0.522089
Train - Epoch 100, Batch: 711, Loss: 0.540033
Train - Epoch 100, Batch: 712, Loss: 0.528927
Train - Epoch 100, Batch: 713, Loss: 0.557533
Train - Epoch 100, Batch: 714, Loss: 0.517004
Train - Epoch 100, Batch: 715, Loss: 0.520038
Train - Epoch 100, Batch: 716, Loss: 0.539187
Train - Epoch 100, Batch: 717, Loss: 0.546428
Train - Epoch 100, Batch: 718, Loss: 0.538409
Train - Epoch 100, Batch: 719, Loss: 0.539907
Train - Epoch 100, Batch: 720, Loss: 0.543145
Train - Epoch 100, Batch: 721, Loss: 0.552983
Train - Epoch 100, Batch: 722, Loss: 0.540364
Train - Epoch 100, Batch: 723, Loss: 0.520728
Train - Epoch 100, Batch: 724, Loss: 0.534593
Train - Epoch 100, Batch: 725, Loss: 0.551746
Train - Epoch 100, Batch: 726, Loss: 0.532317
Train - Epoch 100, Batch: 727, Loss: 0.527466
Train - Epoch 100, Batch: 728, Loss: 0.524586
Train - Epoch 100, Batch: 729, Loss: 0.550159
Train - Epoch 100, Batch: 730, Loss: 0.542050
Train - Epoch 100, Batch: 731, Loss: 0.507325
Train - Epoch 100, Batch: 732, Loss: 0.529439
Train - Epoch 100, Batch: 733, Loss: 0.527843
Train - Epoch 100, Batch: 734, Loss: 0.543342
Train - Epoch 100, Batch: 735, Loss: 0.505213
Train - Epoch 100, Batch: 736, Loss: 0.520975
Train - Epoch 100, Batch: 737, Loss: 0.528254
Train - Epoch 100, Batch: 738, Loss: 0.501919
Train - Epoch 100, Batch: 739, Loss: 0.559560
Train - Epoch 100, Batch: 740, Loss: 0.554588
Train - Epoch 100, Batch: 741, Loss: 0.502716
Train - Epoch 100, Batch: 742, Loss: 0.512342
Train - Epoch 100, Batch: 743, Loss: 0.538936
Train - Epoch 100, Batch: 744, Loss: 0.560605
Train - Epoch 100, Batch: 745, Loss: 0.561909
Train - Epoch 100, Batch: 746, Loss: 0.490047
Train - Epoch 100, Batch: 747, Loss: 0.547502
Train - Epoch 100, Batch: 748, Loss: 0.541621
Train - Epoch 100, Batch: 749, Loss: 0.517131
Train - Epoch 100, Batch: 750, Loss: 0.522658
Train - Epoch 100, Batch: 751, Loss: 0.506837
Train - Epoch 100, Batch: 752, Loss: 0.510850
Train - Epoch 100, Batch: 753, Loss: 0.523142
Train - Epoch 100, Batch: 754, Loss: 0.528852
Train - Epoch 100, Batch: 755, Loss: 0.556790
Train - Epoch 100, Batch: 756, Loss: 0.538878
Train - Epoch 100, Batch: 757, Loss: 0.518199
Train - Epoch 100, Batch: 758, Loss: 0.550333
Train - Epoch 100, Batch: 759, Loss: 0.516263
Train - Epoch 100, Batch: 760, Loss: 0.533111
Train - Epoch 100, Batch: 761, Loss: 0.534838
Train - Epoch 100, Batch: 762, Loss: 0.530658
Train - Epoch 100, Batch: 763, Loss: 0.525459
Train - Epoch 100, Batch: 764, Loss: 0.550686
Train - Epoch 100, Batch: 765, Loss: 0.542918
Train - Epoch 100, Batch: 766, Loss: 0.527832
Train - Epoch 100, Batch: 767, Loss: 0.527982
Train - Epoch 100, Batch: 768, Loss: 0.552145
Train - Epoch 100, Batch: 769, Loss: 0.508422
Train - Epoch 100, Batch: 770, Loss: 0.537852
Train - Epoch 100, Batch: 771, Loss: 0.541587
Train - Epoch 100, Batch: 772, Loss: 0.530823
Train - Epoch 100, Batch: 773, Loss: 0.536422
Train - Epoch 100, Batch: 774, Loss: 0.543872
Train - Epoch 100, Batch: 775, Loss: 0.544052
Train - Epoch 100, Batch: 776, Loss: 0.539185
Train - Epoch 100, Batch: 777, Loss: 0.519282
Train - Epoch 100, Batch: 778, Loss: 0.554517
Train - Epoch 100, Batch: 779, Loss: 0.547176
Train - Epoch 100, Batch: 780, Loss: 0.544739
Train - Epoch 100, Batch: 781, Loss: 0.534676
Train - Epoch 100, Batch: 782, Loss: 0.581384
Train - Epoch 100, Batch: 783, Loss: 0.550095
Train - Epoch 100, Batch: 784, Loss: 0.505729
Train - Epoch 100, Batch: 785, Loss: 0.564475
Train - Epoch 100, Batch: 786, Loss: 0.540826
Train - Epoch 100, Batch: 787, Loss: 0.525406
Train - Epoch 100, Batch: 788, Loss: 0.531891
Train - Epoch 100, Batch: 789, Loss: 0.516632
Train - Epoch 100, Batch: 790, Loss: 0.519361
Train - Epoch 100, Batch: 791, Loss: 0.535995
Train - Epoch 100, Batch: 792, Loss: 0.547362
Train - Epoch 100, Batch: 793, Loss: 0.543651
Train - Epoch 100, Batch: 794, Loss: 0.509454
Train - Epoch 100, Batch: 795, Loss: 0.497995
Train - Epoch 100, Batch: 796, Loss: 0.508753
Train - Epoch 100, Batch: 797, Loss: 0.543905
Train - Epoch 100, Batch: 798, Loss: 0.505660
Train - Epoch 100, Batch: 799, Loss: 0.543552
Train - Epoch 100, Batch: 800, Loss: 0.517088
Train - Epoch 100, Batch: 801, Loss: 0.561934
Train - Epoch 100, Batch: 802, Loss: 0.531140
Train - Epoch 100, Batch: 803, Loss: 0.520673
Train - Epoch 100, Batch: 804, Loss: 0.526519
Train - Epoch 100, Batch: 805, Loss: 0.528477
Train - Epoch 100, Batch: 806, Loss: 0.530754
Train - Epoch 100, Batch: 807, Loss: 0.523205
Train - Epoch 100, Batch: 808, Loss: 0.530622
Train - Epoch 100, Batch: 809, Loss: 0.554294
Train - Epoch 100, Batch: 810, Loss: 0.510843
Train - Epoch 100, Batch: 811, Loss: 0.525105
Train - Epoch 100, Batch: 812, Loss: 0.530937
Train - Epoch 100, Batch: 813, Loss: 0.545409
Train - Epoch 100, Batch: 814, Loss: 0.545266
Train - Epoch 100, Batch: 815, Loss: 0.532220
Train - Epoch 100, Batch: 816, Loss: 0.531871
Train - Epoch 100, Batch: 817, Loss: 0.546988
Train - Epoch 100, Batch: 818, Loss: 0.551267
Train - Epoch 100, Batch: 819, Loss: 0.524017
Train - Epoch 100, Batch: 820, Loss: 0.532633
Train - Epoch 100, Batch: 821, Loss: 0.519699
Train - Epoch 100, Batch: 822, Loss: 0.515217
Train - Epoch 100, Batch: 823, Loss: 0.509130
Train - Epoch 100, Batch: 824, Loss: 0.525823
Train - Epoch 100, Batch: 825, Loss: 0.557877
Train - Epoch 100, Batch: 826, Loss: 0.531972
Train - Epoch 100, Batch: 827, Loss: 0.520830
Train - Epoch 100, Batch: 828, Loss: 0.526594
Train - Epoch 100, Batch: 829, Loss: 0.538416
Train - Epoch 100, Batch: 830, Loss: 0.535970
Train - Epoch 100, Batch: 831, Loss: 0.527565
Train - Epoch 100, Batch: 832, Loss: 0.530577
Train - Epoch 100, Batch: 833, Loss: 0.545620
Train - Epoch 100, Batch: 834, Loss: 0.542358
Train - Epoch 100, Batch: 835, Loss: 0.531301
Train - Epoch 100, Batch: 836, Loss: 0.537685
Train - Epoch 100, Batch: 837, Loss: 0.531502
Train - Epoch 100, Batch: 838, Loss: 0.520724
Train - Epoch 100, Batch: 839, Loss: 0.525373
Train - Epoch 100, Batch: 840, Loss: 0.542200
Train - Epoch 100, Batch: 841, Loss: 0.576050
Train - Epoch 100, Batch: 842, Loss: 0.513014
Train - Epoch 100, Batch: 843, Loss: 0.527991
Train - Epoch 100, Batch: 844, Loss: 0.560246
Train - Epoch 100, Batch: 845, Loss: 0.565406
Train - Epoch 100, Batch: 846, Loss: 0.552618
Train - Epoch 100, Batch: 847, Loss: 0.537694
Train - Epoch 100, Batch: 848, Loss: 0.527782
Train - Epoch 100, Batch: 849, Loss: 0.542840
Train - Epoch 100, Batch: 850, Loss: 0.485740
Train - Epoch 100, Batch: 851, Loss: 0.520949
Train - Epoch 100, Batch: 852, Loss: 0.550544
Train - Epoch 100, Batch: 853, Loss: 0.536726
Train - Epoch 100, Batch: 854, Loss: 0.567963
Train - Epoch 100, Batch: 855, Loss: 0.529941
Train - Epoch 100, Batch: 856, Loss: 0.514571
Train - Epoch 100, Batch: 857, Loss: 0.535431
Train - Epoch 100, Batch: 858, Loss: 0.540165
Train - Epoch 100, Batch: 859, Loss: 0.549095
Train - Epoch 100, Batch: 860, Loss: 0.542722
Train - Epoch 100, Batch: 861, Loss: 0.542898
Train - Epoch 100, Batch: 862, Loss: 0.551433
Train - Epoch 100, Batch: 863, Loss: 0.515410
Train - Epoch 100, Batch: 864, Loss: 0.527382
Train - Epoch 100, Batch: 865, Loss: 0.563579
Train - Epoch 100, Batch: 866, Loss: 0.533385
Train - Epoch 100, Batch: 867, Loss: 0.556508
Train - Epoch 100, Batch: 868, Loss: 0.514259
Train - Epoch 100, Batch: 869, Loss: 0.541931
Train - Epoch 100, Batch: 870, Loss: 0.537082
Train - Epoch 100, Batch: 871, Loss: 0.556606
Train - Epoch 100, Batch: 872, Loss: 0.520020
Train - Epoch 100, Batch: 873, Loss: 0.518095
Train - Epoch 100, Batch: 874, Loss: 0.529489
Train - Epoch 100, Batch: 875, Loss: 0.557436
Train - Epoch 100, Batch: 876, Loss: 0.529980
Train - Epoch 100, Batch: 877, Loss: 0.522319
Train - Epoch 100, Batch: 878, Loss: 0.550371
Train - Epoch 100, Batch: 879, Loss: 0.555363
Train - Epoch 100, Batch: 880, Loss: 0.523386
Train - Epoch 100, Batch: 881, Loss: 0.498018
Train - Epoch 100, Batch: 882, Loss: 0.531682
Train - Epoch 100, Batch: 883, Loss: 0.519722
Train - Epoch 100, Batch: 884, Loss: 0.541427
Train - Epoch 100, Batch: 885, Loss: 0.532982
Train - Epoch 100, Batch: 886, Loss: 0.537398
Train - Epoch 100, Batch: 887, Loss: 0.521186
Train - Epoch 100, Batch: 888, Loss: 0.530738
Train - Epoch 100, Batch: 889, Loss: 0.524738
Train - Epoch 100, Batch: 890, Loss: 0.519859
Train - Epoch 100, Batch: 891, Loss: 0.516104
Train - Epoch 100, Batch: 892, Loss: 0.578080
Train - Epoch 100, Batch: 893, Loss: 0.506768
Train - Epoch 100, Batch: 894, Loss: 0.530805
Train - Epoch 100, Batch: 895, Loss: 0.540174
Train - Epoch 100, Batch: 896, Loss: 0.518644
Train - Epoch 100, Batch: 897, Loss: 0.545878
Train - Epoch 100, Batch: 898, Loss: 0.534579
Train - Epoch 100, Batch: 899, Loss: 0.525248
Train - Epoch 100, Batch: 900, Loss: 0.534939
Train - Epoch 100, Batch: 901, Loss: 0.533377
Train - Epoch 100, Batch: 902, Loss: 0.528829
Train - Epoch 100, Batch: 903, Loss: 0.532223
Train - Epoch 100, Batch: 904, Loss: 0.524952
Train - Epoch 100, Batch: 905, Loss: 0.524384
Train - Epoch 100, Batch: 906, Loss: 0.568934
Train - Epoch 100, Batch: 907, Loss: 0.575689
Train - Epoch 100, Batch: 908, Loss: 0.520798
Train - Epoch 100, Batch: 909, Loss: 0.560102
Train - Epoch 100, Batch: 910, Loss: 0.517104
Train - Epoch 100, Batch: 911, Loss: 0.504796
Train - Epoch 100, Batch: 912, Loss: 0.537320
Train - Epoch 100, Batch: 913, Loss: 0.520362
Train - Epoch 100, Batch: 914, Loss: 0.556982
Train - Epoch 100, Batch: 915, Loss: 0.538061
Train - Epoch 100, Batch: 916, Loss: 0.536096
Train - Epoch 100, Batch: 917, Loss: 0.537764
Train - Epoch 100, Batch: 918, Loss: 0.540380
Train - Epoch 100, Batch: 919, Loss: 0.504203
Train - Epoch 100, Batch: 920, Loss: 0.507862
Train - Epoch 100, Batch: 921, Loss: 0.540951
Train - Epoch 100, Batch: 922, Loss: 0.537414
Train - Epoch 100, Batch: 923, Loss: 0.534531
Train - Epoch 100, Batch: 924, Loss: 0.541876
Train - Epoch 100, Batch: 925, Loss: 0.518654
Train - Epoch 100, Batch: 926, Loss: 0.517617
Train - Epoch 100, Batch: 927, Loss: 0.526123
Train - Epoch 100, Batch: 928, Loss: 0.536743
Train - Epoch 100, Batch: 929, Loss: 0.548569
Train - Epoch 100, Batch: 930, Loss: 0.509373
Train - Epoch 100, Batch: 931, Loss: 0.520653
Train - Epoch 100, Batch: 932, Loss: 0.501793
Train - Epoch 100, Batch: 933, Loss: 0.531799
Train - Epoch 100, Batch: 934, Loss: 0.538977
Train - Epoch 100, Batch: 935, Loss: 0.562579
Train - Epoch 100, Batch: 936, Loss: 0.528641
Train - Epoch 100, Batch: 937, Loss: 0.550220
Train - Epoch 100, Batch: 938, Loss: 0.565145
Train - Epoch 100, Batch: 939, Loss: 0.503562
Train - Epoch 100, Batch: 940, Loss: 0.533959
Train - Epoch 100, Batch: 941, Loss: 0.534070
Train - Epoch 100, Batch: 942, Loss: 0.524386
Train - Epoch 100, Batch: 943, Loss: 0.536904
Train - Epoch 100, Batch: 944, Loss: 0.534377
Train - Epoch 100, Batch: 945, Loss: 0.537798
Train - Epoch 100, Batch: 946, Loss: 0.536356
Train - Epoch 100, Batch: 947, Loss: 0.532432
Train - Epoch 100, Batch: 948, Loss: 0.545630
Train - Epoch 100, Batch: 949, Loss: 0.538899
Train - Epoch 100, Batch: 950, Loss: 0.535702
Train - Epoch 100, Batch: 951, Loss: 0.544423
Train - Epoch 100, Batch: 952, Loss: 0.534616
Train - Epoch 100, Batch: 953, Loss: 0.559297
Train - Epoch 100, Batch: 954, Loss: 0.524751
Train - Epoch 100, Batch: 955, Loss: 0.526556
Train - Epoch 100, Batch: 956, Loss: 0.527891
Train - Epoch 100, Batch: 957, Loss: 0.534875
Train - Epoch 100, Batch: 958, Loss: 0.530111
Train - Epoch 100, Batch: 959, Loss: 0.530571
Train - Epoch 100, Batch: 960, Loss: 0.533086
Train - Epoch 100, Batch: 961, Loss: 0.559950
Train - Epoch 100, Batch: 962, Loss: 0.515827
Train - Epoch 100, Batch: 963, Loss: 0.539423
Train - Epoch 100, Batch: 964, Loss: 0.531597
Train - Epoch 100, Batch: 965, Loss: 0.526158
Train - Epoch 100, Batch: 966, Loss: 0.542694
Train - Epoch 100, Batch: 967, Loss: 0.544790
Train - Epoch 100, Batch: 968, Loss: 0.522657
Train - Epoch 100, Batch: 969, Loss: 0.541005
Train - Epoch 100, Batch: 970, Loss: 0.555494
Train - Epoch 100, Batch: 971, Loss: 0.554839
Train - Epoch 100, Batch: 972, Loss: 0.542238
Train - Epoch 100, Batch: 973, Loss: 0.529277
Train - Epoch 100, Batch: 974, Loss: 0.512350
Train - Epoch 100, Batch: 975, Loss: 0.536267
Train - Epoch 100, Batch: 976, Loss: 0.533609
Train - Epoch 100, Batch: 977, Loss: 0.520184
Train - Epoch 100, Batch: 978, Loss: 0.488898
Train - Epoch 100, Batch: 979, Loss: 0.535940
Train - Epoch 100, Batch: 980, Loss: 0.519577
Train - Epoch 100, Batch: 981, Loss: 0.512063
Train - Epoch 100, Batch: 982, Loss: 0.509011
Train - Epoch 100, Batch: 983, Loss: 0.540863
Train - Epoch 100, Batch: 984, Loss: 0.504577
Train - Epoch 100, Batch: 985, Loss: 0.514667
Train - Epoch 100, Batch: 986, Loss: 0.519405
Train - Epoch 100, Batch: 987, Loss: 0.513397
Train - Epoch 100, Batch: 988, Loss: 0.527082
Train - Epoch 100, Batch: 989, Loss: 0.521045
Train - Epoch 100, Batch: 990, Loss: 0.529435
Train - Epoch 100, Batch: 991, Loss: 0.517592
Train - Epoch 100, Batch: 992, Loss: 0.554796
Train - Epoch 100, Batch: 993, Loss: 0.529492
Train - Epoch 100, Batch: 994, Loss: 0.544868
Train - Epoch 100, Batch: 995, Loss: 0.538819
Train - Epoch 100, Batch: 996, Loss: 0.554992
Train - Epoch 100, Batch: 997, Loss: 0.503506
Train - Epoch 100, Batch: 998, Loss: 0.557653
Train - Epoch 100, Batch: 999, Loss: 0.546116
Train - Epoch 100, Batch: 1000, Loss: 0.516121
Train - Epoch 100, Batch: 1001, Loss: 0.545113
Train - Epoch 100, Batch: 1002, Loss: 0.549024
Train - Epoch 100, Batch: 1003, Loss: 0.549876
Train - Epoch 100, Batch: 1004, Loss: 0.568293
Train - Epoch 100, Batch: 1005, Loss: 0.542808
Train - Epoch 100, Batch: 1006, Loss: 0.507910
Train - Epoch 100, Batch: 1007, Loss: 0.547999
Train - Epoch 100, Batch: 1008, Loss: 0.530356
Train - Epoch 100, Batch: 1009, Loss: 0.538771
Train - Epoch 100, Batch: 1010, Loss: 0.508103
Train - Epoch 100, Batch: 1011, Loss: 0.559302
Train - Epoch 100, Batch: 1012, Loss: 0.533032
Train - Epoch 100, Batch: 1013, Loss: 0.546947
Train - Epoch 100, Batch: 1014, Loss: 0.553853
Train - Epoch 100, Batch: 1015, Loss: 0.511964
Train - Epoch 100, Batch: 1016, Loss: 0.519101
Train - Epoch 100, Batch: 1017, Loss: 0.547880
Train - Epoch 100, Batch: 1018, Loss: 0.562345
Train - Epoch 100, Batch: 1019, Loss: 0.527645
Train - Epoch 100, Batch: 1020, Loss: 0.545319
Train - Epoch 100, Batch: 1021, Loss: 0.580691
training_time:: 120.73186755180359
training time full:: 120.73204731941223
provenance prepare time:: 0.0
here
Test Avg. Loss: 0.001047, Accuracy: 0.744914, F1 Score: 0.751213
</Training>
torch.Size([522910, 54])
tensor([336724, 387882, 257850,  ...,  72786,  22973,  44254])
<results lr="1" epochs="200" bz="512" remove_ratio="0.15" sampling_type="targeted_informed">
<Baseline>
data dimension:: [522910, 54]
tensor([174084, 309253, 149514, 112659, 110612, 112665, 360477, 499742, 434216,
         94249, 432171, 114734, 489541, 409671, 479306, 471115, 157772,   4171,
        135254, 501855, 313443, 143468, 120944, 120954, 239739, 272520, 141450,
        145550, 493712, 161941, 440470, 307352, 467102, 411807, 118951, 221358,
        186558, 389324,  45265, 110801, 329940,  22749, 516320, 366816, 397536,
        317670, 501992, 354538,  22764, 162038])
Epoch:0 Batch: 1021 Baseline Loss 0.5252181816535899
Epoch:100 Batch: 1021 Baseline Loss 0.5136061465553569
training time is 145.65641951560974
overhead:: 0
overhead2:: 35.246238231658936
overhead3:: 0
memory usage:: 3977814016
time_baseline:: 145.99145245552063
Test Avg. Loss: 0.001171, Accuracy: 0.680768, F1 Score: 0.721644
model difference (l2 norm): tensor(6.9537, dtype=torch.float64)
Test Avg. Loss: 0.001171, Accuracy: 0.680768, F1 Score: 0.721644
Remove Test Avg. Loss: 0.002254, Accuracy: 0.277169, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001164, Accuracy: 0.680670, F1 Score: 0.721271
</Baseline>
<Deltagrad period="2">
data dimension:: [522910, 54]
overhead2:: 35.89296913146973
overhead3:: 63.31984210014343
overhead4:: 28.695890426635742
overhead5:: 0
memory usage:: 4105338880
time_deltagrad:: 252.56486892700195
model difference (l2 norm): tensor(0.1718, dtype=torch.float64)
Test Avg. Loss: 0.001174, Accuracy: 0.679460, F1 Score: 0.721914
Remove Test Avg. Loss: 0.002276, Accuracy: 0.272056, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001167, Accuracy: 0.679308, F1 Score: 0.721526
</Deltagrad>
<Deltagrad period="5">
data dimension:: [522910, 54]
overhead2:: 13.69851541519165
overhead3:: 32.46262311935425
overhead4:: 10.652150630950928
overhead5:: 0
memory usage:: 4105302016
time_deltagrad:: 190.64102959632874
model difference (l2 norm): tensor(0.2895, dtype=torch.float64)
Test Avg. Loss: 0.001170, Accuracy: 0.681130, F1 Score: 0.722670
Remove Test Avg. Loss: 0.002248, Accuracy: 0.276620, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001163, Accuracy: 0.680960, F1 Score: 0.722187
</Deltagrad>
<Deltagrad period="10">
data dimension:: [522910, 54]
overhead2:: 6.843276739120483
overhead3:: 23.056602478027344
overhead4:: 5.229404926300049
overhead5:: 0
memory usage:: 4105297920
time_deltagrad:: 168.17860388755798
model difference (l2 norm): tensor(0.3449, dtype=torch.float64)
Test Avg. Loss: 0.001169, Accuracy: 0.680837, F1 Score: 0.722628
Remove Test Avg. Loss: 0.002245, Accuracy: 0.276404, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001163, Accuracy: 0.680589, F1 Score: 0.722161
</Deltagrad>
<Deltagrad period="20">
data dimension:: [522910, 54]
overhead2:: 3.607361316680908
overhead3:: 18.62015724182129
overhead4:: 2.569789409637451
overhead5:: 0
memory usage:: 4105297920
time_deltagrad:: 161.7962806224823
model difference (l2 norm): tensor(0.3949, dtype=torch.float64)
Test Avg. Loss: 0.001168, Accuracy: 0.681233, F1 Score: 0.722586
Remove Test Avg. Loss: 0.002235, Accuracy: 0.276416, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001161, Accuracy: 0.681113, F1 Score: 0.722202
</Deltagrad>
<Deltagrad period="50">
data dimension:: [522910, 54]
overhead2:: 1.4344289302825928
overhead3:: 15.4514000415802
overhead4:: 1.0310938358306885
overhead5:: 0
memory usage:: 4105633792
time_deltagrad:: 154.01882696151733
model difference (l2 norm): tensor(0.6164, dtype=torch.float64)
Test Avg. Loss: 0.001158, Accuracy: 0.685605, F1 Score: 0.717566
Remove Test Avg. Loss: 0.002149, Accuracy: 0.292799, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001152, Accuracy: 0.685915, F1 Score: 0.717694
</Deltagrad>
<Deltagrad period="75">
data dimension:: [522910, 54]
overhead2:: 0.9572501182556152
overhead3:: 14.766170263290405
overhead4:: 0.6882109642028809
overhead5:: 0
memory usage:: 4105220096
time_deltagrad:: 151.86853647232056
model difference (l2 norm): tensor(0.9588, dtype=torch.float64)
Test Avg. Loss: 0.001193, Accuracy: 0.675037, F1 Score: 0.718962
Remove Test Avg. Loss: 0.002395, Accuracy: 0.239303, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001186, Accuracy: 0.675309, F1 Score: 0.718854
</Deltagrad>
<Deltagrad period="100">
data dimension:: [522910, 54]
overhead2:: 0.7115464210510254
overhead3:: 14.667258262634277
overhead4:: 0.5184364318847656
overhead5:: 0
memory usage:: 4105318400
time_deltagrad:: 150.6433551311493
model difference (l2 norm): tensor(2.0813, dtype=torch.float64)
Test Avg. Loss: 0.001512, Accuracy: 0.613834, F1 Score: 0.709489
Remove Test Avg. Loss: 0.003832, Accuracy: 0.063122, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001503, Accuracy: 0.614016, F1 Score: 0.709501
</Deltagrad>
<Deltagrad period="200">
data dimension:: [522910, 54]
overhead2:: 0.43538951873779297
overhead3:: 14.179772138595581
overhead4:: 0.25961995124816895
overhead5:: 0
memory usage:: 4105302016
time_deltagrad:: 147.5426688194275
model difference (l2 norm): tensor(1.3808, dtype=torch.float64)
Test Avg. Loss: 0.001184, Accuracy: 0.679426, F1 Score: 0.714701
Remove Test Avg. Loss: 0.002307, Accuracy: 0.256642, F1 Score: 0.000000
Remain Test Avg. Loss: 0.001177, Accuracy: 0.679027, F1 Score: 0.714015
</Deltagrad>
</results>
</data>
